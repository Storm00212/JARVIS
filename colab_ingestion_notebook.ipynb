{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Storm00212/JARVIS/blob/main/colab_ingestion_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "930bb34e",
      "metadata": {
        "id": "930bb34e"
      },
      "source": [
        "\n",
        "# JARVIS RAG Ingestion Notebook (Colab-ready)\n",
        "\n",
        "**Purpose:** This notebook walks you through an end-to-end prototype ingestion pipeline that:\n",
        "- Accepts PDF / DOCX / PPTX documents\n",
        "- Extracts clean text (with optional OCR)\n",
        "- Splits documents into semantic chunks\n",
        "- Generates embeddings for chunks\n",
        "- Stores chunks + embeddings into a local Chroma vector store\n",
        "- Exposes a simple `ask(question)` function that uses retrieval + prompt assembly (RAG)\n",
        "\n",
        "**Notes & assumptions**\n",
        "- Designed for Google Colab interactive use.\n",
        "- Includes a sample path from this session: `/mnt/data/jarvis-ai.zip` which you can inspect or replace with your own uploads.\n",
        "- Each code cell includes detailed comments to help you follow along.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7dd3208",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7dd3208",
        "outputId": "bd20ea94-f7a3-4798-b0cd-b41527383a37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mDependencies installed (or already present).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# SECTION 1: Install required packages\n",
        "# Run this cell in Google Colab to install dependencies. It may take 1-2 minutes.Additional dependencies to be added\n",
        "!pip install --quiet pypdf python-docx python-pptx sentence-transformers chromadb langchain tiktoken PyMuPDF langchain_text_splitters faiss-cpu llama-cpp-python together llama-cpp-python==0.2.30 langchain langchain-community langchain-core\n",
        "print('Dependencies installed (or already present).')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdb1df0a",
      "metadata": {
        "id": "cdb1df0a"
      },
      "source": [
        "\n",
        "## SECTION 2: Upload files (use UI) or use sample path\n",
        "\n",
        "You can upload files interactively using the cell below, or skip upload and use the sample file `'/mnt/data/jarvis-ai.zip'` if present.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o6ERR0AEhhA6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6ERR0AEhhA6",
        "outputId": "1df2ae8a-3308-46a3-d162-e025f296868d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IvxHIzeqiCkB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvxHIzeqiCkB",
        "outputId": "f13bf88c-3219-4615-92f3-2e46daf387ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base project folder: /content/drive/MyDrive/jarvis-ai\n",
            "Raw data folder: /content/drive/MyDrive/jarvis-ai/data/raw\n"
          ]
        }
      ],
      "source": [
        "# setting up the directory to upload the files\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/jarvis-ai\"\n",
        "RAW_DATA_DIR = f\"{BASE_DIR}/data/raw\"\n",
        "\n",
        "# Create folders if they don't exist\n",
        "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Base project folder:\", BASE_DIR)\n",
        "print(\"Raw data folder:\", RAW_DATA_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HD04XWpniZKa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "HD04XWpniZKa",
        "outputId": "9ccc0873-caa8-4fe4-e3b0-a5da4f1620b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-69bd8950-c1dc-479a-ae9c-82321715fd2b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-69bd8950-c1dc-479a-ae9c-82321715fd2b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2040593585.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m \u001b[0;31m# Import shutil for cross-device moves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# choose multiple files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# uploading files to directory\n",
        "from google.colab import files\n",
        "import shutil # Import shutil for cross-device moves\n",
        "\n",
        "uploaded_files = files.upload()  # choose multiple files\n",
        "\n",
        "\n",
        "# Move uploaded files into the Drive folder\n",
        "for filename in uploaded_files.keys():\n",
        "    src = f\"/content/{filename}\"\n",
        "    dst = f\"{RAW_DATA_DIR}/{filename}\"\n",
        "    print(f\"Moving {src} → {dst}\")\n",
        "    # Use shutil.move to handle cross-device links (copy then delete)\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "print(\"\\nUpload complete!\")\n",
        "\n",
        "print(\"Files in your study notes folder:\")\n",
        "print(os.listdir(RAW_DATA_DIR))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qn_1KJIyiqQv",
      "metadata": {
        "id": "Qn_1KJIyiqQv"
      },
      "source": [
        "# Reading the pdfs from my drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tuR54l3FiuiA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuR54l3FiuiA",
        "outputId": "56089e2a-96a5-408f-9cfa-e07ea33f5f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracting PDF: 1. Amplifiers with Negative Feedback (2).pdf\n",
            "Extracting PDF: 3.1 Resources  (2).pdf\n",
            "Extracting PDF: churchillbrown (2).pdf\n",
            "Extracting PDF: EEE 3208 ELECTROMAGNETICS III lec1 notes (2).pdf\n",
            "Extracting PDF: eee.eti.3104.cat.ii.make_up.ms (2).pdf\n",
            "Extracting PDF: eee3102 [1-20] (2).pdf\n",
            "Extracting PDF: EEE 2206_EET 2204_Electromagnetics I_Exam (2).pdf\n",
            "Extracting PDF: eee3102 [21-33] (2).pdf\n",
            "Extracting PDF: EEE_ETI3105_Assignment ONE (2).pdf\n",
            "Extracting PDF: Design_of_Analog_Filters_Rolf_Schaumann (2).pdf\n",
            "Extracting PDF: digielec (2).pdf\n",
            "Extracting PDF: EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (3).pdf\n",
            "Extracting PDF: eee3104eti3104 [1-68] (2).pdf\n",
            "Extracting PDF: Electromagnetics (2).pdf\n",
            "Extracting PDF: A textbook of Electrical Technology B. L. Thereja All Volumes ( PDFDrive (2).pdf\n",
            "Extracting PDF: EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 (2).pdf\n",
            "Extracting PDF: EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (1) (2).pdf\n",
            "Extracting PDF: EEE2205 Electromagnetics I (2).pdf\n",
            "Extracting PDF: 3.2 Past Papers   (2).pdf\n",
            "Extracting PPTX: EEE 3207 ELECTRICAL MACHINES 2 (2).pptx\n",
            "Extracting PDF: Complex analysis Q&A (2).pdf\n",
            "Extracting PDF: eee3102 [49-67] (2).pdf\n",
            "Extracting PDF: EEE 3101_Analogue Electronics_Exam (2).pdf\n",
            "Extracting PDF: EEE_ETI3105_CAT 2 (2).pdf\n",
            "Extracting PDF: DOC-20250908-WA0053. (2).pdf\n",
            "Extracting PDF: EEE2206cbd ELECTROMAGNETICS I (2).pdf\n",
            "Extracting PDF: DOC-20250827-WA0009. (2).pdf\n",
            "Extracting PDF: Complex analysis Q&A2 (2).pdf\n",
            "Extracting PDF: EEE2205 Electromagnetics I ready (2).pdf\n",
            "Extracting PDF: Electromagnetic_Field_Theory_U_A_Bakshi. - By EasyEngineering.net (2).pdf\n",
            "Extracting PDF: Electronics Fundamentals Circuits Devices and Applications 8th Edition By David M Buchla and Thomas L Floyd (2).pdf\n",
            "Extracting PDF: assignment_1 (2).pdf\n",
            "Extracting PDF: EEE 2305 - Electromagnetics I - Exam - 2017-18 sem I (2) (2).pdf\n",
            "Extracting PDF: eee.eti.3104.model.solutions.cat.ii (2).pdf\n",
            "Extracting PDF: Document from . (2).pdf\n",
            "Extracting PDF: applied-numerical-methods-with-matlab-for-engineers-and-scientists-4nbsped-0073397962-9780073397962_compress (2).pdf\n",
            "Extracting PDF: EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 ready (2).pdf\n",
            "Extracting PDF: eee3104eti3104 (2).pdf\n",
            "Extracting PDF: elecmag-i-electromagnetics... (2).pdf\n",
            "Extracting PDF: EEE 3101cbd_ANALOGUE ELECTRONICS I EXAM 2019-2020 (2).pdf\n",
            "Extracting PDF: EEE 3103 ELECTROMAGNETICS II (2).pdf\n",
            "Extracting PDF: guru_b-s-_hiziroglu_h-r-_electromagnetic_field_bookzz-org (2).pdf\n",
            "Extracting PDF: Lecture 1_BJT Configurations & Their Characteristics (2).pdf\n",
            "Extracting PDF: Lecture 8-Laplace Transform (2).pdf\n",
            "Extracting PDF: LECTURE 5-TRANSFORMER TESTS & EFFICIENCY (2).pdf\n",
            "Extracting PDF: Numerical-Methods-Rao-V.-Dukkipati-2010 (2).pdf\n",
            "Extracting PDF: Sadiqu (2).pdf\n",
            "Extracting PDF: LECTURE 8-DC MOTORS (2).pdf\n",
            "Extracting PDF: Topic 3_Single Stage Transistor Amplifiers (1) (2).pdf\n",
            "Extracting PDF: LECTURE 7-TYPES OF DC GENERATORS (2).pdf\n",
            "Extracting PDF: Topic 4_MOSFETS (2).pdf\n",
            "Extracting PDF: Topic 2_Small Signal Amplifiers (2).pdf\n",
            "Extracting PDF: SMA 3121 Topic 10 Conformal (1) (2).pdf\n",
            "Extracting PDF: Topic 3_Multistage Transistor Amplifiers (2).pdf\n",
            "Extracting PDF: Topic 3_Bipolar Junction Transistors (2) (2).pdf\n",
            "Extracting PDF: LECTURE 4-EQUIVALENT CIRCUITS_TRANSFORMERS  (2).pdf\n",
            "Extracting PDF: Lecture 2_Large Signal Amplifiers_1 of 2 (2).pdf\n",
            "Extracting PDF: Q5 (2).pdf\n",
            "Extracting PDF: SMA 3121 Topic 7 Laurent series (1) (2).pdf\n",
            "Extracting PDF: LECTURE 1-MAGNETIC CIRCUITS (2).pdf\n",
            "Extracting PDF: LECTURE 6-DC MACHINE FUNDAMENTALS (2).pdf\n",
            "Extracting PDF: Lecture 7-Filters (2).pdf\n",
            "Extracting PDF: Topic 3_Single Stage Transistor Amplifiers (3).pdf\n",
            "Extracting PDF: Lecture 3_Large Signal Amplifiers_2 of 2 (2).pdf\n",
            "Extracting PDF: SMA 3121 Topic 9 Using Residue (1) (2).pdf\n",
            "Extracting PDF: MAGNETIC FLUX DENSITY (2).pdf\n",
            "Extracting PDF: V.K-Mehta-Principles-of-Electronics (2).pdf\n",
            "Extracting PDF: Q1to4 (2).pdf\n",
            "Extracting PDF: model.solutions (2).pdf\n",
            "Extracting PDF: SMA 3121 Topic 4 Cauchy formular (1) (2).pdf\n",
            "Extracting PDF: LECTURE 3-PRACTICAL TRANSFORMERS (2).pdf\n",
            "Extracting PDF: LECTURE 2-TRANSFORMERS (2).pdf\n",
            "Extracting PDF: Lecture 05_Three Phase AC circuits (2).pdf\n",
            "\n",
            "✔ Extraction complete!\n",
            "Total loaded documents: 73\n"
          ]
        }
      ],
      "source": [
        "# STEP 1 — Load PDFs from Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import fitz  # PyMuPDF for PDFs\n",
        "import docx  # DOCX reader\n",
        "from pptx import Presentation  # PPTX reader\n",
        "\n",
        "# CHANGE THIS to your folder\n",
        "DATA_FOLDER = \"/content/drive/MyDrive/jarvis-ai/data/raw\"\n",
        "\n",
        "documents = {}  # filename → extracted text\n",
        "\n",
        "\n",
        "# function to read docx\n",
        "def extract_docx(path):\n",
        "    doc = docx.Document(path)\n",
        "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "    return text\n",
        "\n",
        "\n",
        "# function to read pptx\n",
        "def extract_pptx(path):\n",
        "    prs = Presentation(path)\n",
        "    text = []\n",
        "\n",
        "    for slide in prs.slides:\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text\"):\n",
        "                text.append(shape.text)\n",
        "\n",
        "    return \"\\n\".join(text)\n",
        "\n",
        "\n",
        "# function to read pdf\n",
        "def extract_pdf(path):\n",
        "    doc = fitz.open(path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text(\"text\")\n",
        "    return text\n",
        "\n",
        "\n",
        "# iterate through the study notes folder\n",
        "for filename in os.listdir(DATA_FOLDER):\n",
        "    path = os.path.join(DATA_FOLDER, filename)\n",
        "\n",
        "    if filename.lower().endswith(\".pdf\"):\n",
        "        print(f\"Extracting PDF: {filename}\")\n",
        "        documents[filename] = extract_pdf(path)\n",
        "\n",
        "    elif filename.lower().endswith(\".docx\"):\n",
        "        print(f\"Extracting DOCX: {filename}\")\n",
        "        documents[filename] = extract_docx(path)\n",
        "\n",
        "    elif filename.lower().endswith(\".pptx\"):\n",
        "        print(f\"Extracting PPTX: {filename}\")\n",
        "        documents[filename] = extract_pptx(path)\n",
        "\n",
        "    else:\n",
        "        print(f\"Skipping unsupported file: {filename}\")\n",
        "\n",
        "\n",
        "print(\"\\n✔ Extraction complete!\")\n",
        "print(f\"Total loaded documents: {len(documents)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A5WrXbE1m8Sr",
      "metadata": {
        "id": "A5WrXbE1m8Sr"
      },
      "source": [
        "# Next we will split the documents into chunks before building the FAISS AND EMBEDDINGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tu5GP1Wwm50u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu5GP1Wwm50u",
        "outputId": "d6363f72-48d7-46fe-87dc-582c7e514e53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunking: 1. Amplifiers with Negative Feedback (2).pdf\n",
            "Chunking: 3.1 Resources  (2).pdf\n",
            "Chunking: churchillbrown (2).pdf\n",
            "Chunking: EEE 3208 ELECTROMAGNETICS III lec1 notes (2).pdf\n",
            "Chunking: eee.eti.3104.cat.ii.make_up.ms (2).pdf\n",
            "Chunking: eee3102 [1-20] (2).pdf\n",
            "Chunking: EEE 2206_EET 2204_Electromagnetics I_Exam (2).pdf\n",
            "Chunking: eee3102 [21-33] (2).pdf\n",
            "Chunking: EEE_ETI3105_Assignment ONE (2).pdf\n",
            "Chunking: Design_of_Analog_Filters_Rolf_Schaumann (2).pdf\n",
            "Chunking: digielec (2).pdf\n",
            "Chunking: EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (3).pdf\n",
            "Chunking: eee3104eti3104 [1-68] (2).pdf\n",
            "Chunking: Electromagnetics (2).pdf\n",
            "Chunking: A textbook of Electrical Technology B. L. Thereja All Volumes ( PDFDrive (2).pdf\n",
            "Chunking: EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 (2).pdf\n",
            "Chunking: EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (1) (2).pdf\n",
            "Chunking: EEE2205 Electromagnetics I (2).pdf\n",
            "Chunking: 3.2 Past Papers   (2).pdf\n",
            "Chunking: EEE 3207 ELECTRICAL MACHINES 2 (2).pptx\n",
            "Chunking: Complex analysis Q&A (2).pdf\n",
            "Chunking: eee3102 [49-67] (2).pdf\n",
            "Chunking: EEE 3101_Analogue Electronics_Exam (2).pdf\n",
            "Chunking: EEE_ETI3105_CAT 2 (2).pdf\n",
            "Chunking: DOC-20250908-WA0053. (2).pdf\n",
            "Chunking: EEE2206cbd ELECTROMAGNETICS I (2).pdf\n",
            "Chunking: DOC-20250827-WA0009. (2).pdf\n",
            "Chunking: Complex analysis Q&A2 (2).pdf\n",
            "Chunking: EEE2205 Electromagnetics I ready (2).pdf\n",
            "Chunking: Electromagnetic_Field_Theory_U_A_Bakshi. - By EasyEngineering.net (2).pdf\n",
            "Chunking: Electronics Fundamentals Circuits Devices and Applications 8th Edition By David M Buchla and Thomas L Floyd (2).pdf\n",
            "Chunking: assignment_1 (2).pdf\n",
            "Chunking: EEE 2305 - Electromagnetics I - Exam - 2017-18 sem I (2) (2).pdf\n",
            "Chunking: eee.eti.3104.model.solutions.cat.ii (2).pdf\n",
            "Chunking: Document from . (2).pdf\n",
            "Chunking: applied-numerical-methods-with-matlab-for-engineers-and-scientists-4nbsped-0073397962-9780073397962_compress (2).pdf\n",
            "Chunking: EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 ready (2).pdf\n",
            "Chunking: eee3104eti3104 (2).pdf\n",
            "Chunking: elecmag-i-electromagnetics... (2).pdf\n",
            "Chunking: EEE 3101cbd_ANALOGUE ELECTRONICS I EXAM 2019-2020 (2).pdf\n",
            "Chunking: EEE 3103 ELECTROMAGNETICS II (2).pdf\n",
            "Chunking: guru_b-s-_hiziroglu_h-r-_electromagnetic_field_bookzz-org (2).pdf\n",
            "Chunking: Lecture 1_BJT Configurations & Their Characteristics (2).pdf\n",
            "Chunking: Lecture 8-Laplace Transform (2).pdf\n",
            "Chunking: LECTURE 5-TRANSFORMER TESTS & EFFICIENCY (2).pdf\n",
            "Chunking: Numerical-Methods-Rao-V.-Dukkipati-2010 (2).pdf\n",
            "Chunking: Sadiqu (2).pdf\n",
            "Chunking: LECTURE 8-DC MOTORS (2).pdf\n",
            "Chunking: Topic 3_Single Stage Transistor Amplifiers (1) (2).pdf\n",
            "Chunking: LECTURE 7-TYPES OF DC GENERATORS (2).pdf\n",
            "Chunking: Topic 4_MOSFETS (2).pdf\n",
            "Chunking: Topic 2_Small Signal Amplifiers (2).pdf\n",
            "Chunking: SMA 3121 Topic 10 Conformal (1) (2).pdf\n",
            "Chunking: Topic 3_Multistage Transistor Amplifiers (2).pdf\n",
            "Chunking: Topic 3_Bipolar Junction Transistors (2) (2).pdf\n",
            "Chunking: LECTURE 4-EQUIVALENT CIRCUITS_TRANSFORMERS  (2).pdf\n",
            "Chunking: Lecture 2_Large Signal Amplifiers_1 of 2 (2).pdf\n",
            "Chunking: Q5 (2).pdf\n",
            "Chunking: SMA 3121 Topic 7 Laurent series (1) (2).pdf\n",
            "Chunking: LECTURE 1-MAGNETIC CIRCUITS (2).pdf\n",
            "Chunking: LECTURE 6-DC MACHINE FUNDAMENTALS (2).pdf\n",
            "Chunking: Lecture 7-Filters (2).pdf\n",
            "Chunking: Topic 3_Single Stage Transistor Amplifiers (3).pdf\n",
            "Chunking: Lecture 3_Large Signal Amplifiers_2 of 2 (2).pdf\n",
            "Chunking: SMA 3121 Topic 9 Using Residue (1) (2).pdf\n",
            "Chunking: MAGNETIC FLUX DENSITY (2).pdf\n",
            "Chunking: V.K-Mehta-Principles-of-Electronics (2).pdf\n",
            "Chunking: Q1to4 (2).pdf\n",
            "Chunking: model.solutions (2).pdf\n",
            "Chunking: SMA 3121 Topic 4 Cauchy formular (1) (2).pdf\n",
            "Chunking: LECTURE 3-PRACTICAL TRANSFORMERS (2).pdf\n",
            "Chunking: LECTURE 2-TRANSFORMERS (2).pdf\n",
            "Chunking: Lecture 05_Three Phase AC circuits (2).pdf\n",
            "\n",
            "✔ Chunking complete!\n"
          ]
        }
      ],
      "source": [
        "# CREATING THE SPLITTER\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Recursive splitter -- best for mixed text types\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    separators=[\n",
        "        \"\\n\\n\",  # prefer splitting at paragraphs\n",
        "        \"\\n\",\n",
        "        \". \",\n",
        "        \"! \",\n",
        "        \"? \",\n",
        "        \"; \",\n",
        "        \", \",\n",
        "        \" \",    # fallback: whitespace\n",
        "        \"\"      # absolute fallback\n",
        "    ]\n",
        ")\n",
        "\n",
        "all_chunks = {}  # filename → list of text chunks\n",
        "\n",
        "for filename, text in documents.items():\n",
        "    print(f\"Chunking: {filename}\")\n",
        "\n",
        "    chunks = splitter.split_text(text)\n",
        "    all_chunks[filename] = chunks\n",
        "\n",
        "print(\"\\n✔ Chunking complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dtDUEjOsFVN",
      "metadata": {
        "id": "2dtDUEjOsFVN"
      },
      "source": [
        "# Embedding and FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IYq4LT24sO1e",
      "metadata": {
        "id": "IYq4LT24sO1e"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# FREE embedding model\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def embed_text(texts):\n",
        "    return embedding_model.encode(texts, convert_to_numpy=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TVL8xyQYwUV1",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TVL8xyQYwUV1",
        "outputId": "8d60a38d-2e6d-40ae-e135-8b0321912650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index size: 22293\n"
          ]
        }
      ],
      "source": [
        "# creating the faiss vector store\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Flatten chunks\n",
        "texts = []\n",
        "meta = []\n",
        "for filename, chunks in all_chunks.items():\n",
        "    for chunk in chunks:\n",
        "        texts.append(chunk)\n",
        "        meta.append({\"source\": filename})\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = embed_text(texts)\n",
        "\n",
        "# Build FAISS index\n",
        "dim = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(embeddings)\n",
        "\n",
        "print(f\"FAISS index size: {index.ntotal}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D4XCGVF9ABm8",
      "metadata": {
        "id": "D4XCGVF9ABm8"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "FAISS_PATH = \"/content/drive/MyDrive/jarvis-ai/faiss_index\"\n",
        "\n",
        "np.save(FAISS_PATH + \"_vectors.npy\", embeddings)\n",
        "with open(FAISS_PATH + \"_metadata.pkl\", \"wb\") as f:\n",
        "    pickle.dump(meta, f)\n",
        "\n",
        "faiss.write_index(index, FAISS_PATH + \"_index.faiss\")\n",
        "\n",
        "print(\"✔ Vectorstore saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ROof42ziAaTY",
      "metadata": {
        "id": "ROof42ziAaTY"
      },
      "outputs": [],
      "source": [
        "from llama_cpp import Llama\n",
        "import os\n",
        "\n",
        "# Download the model file if it doesn't exist\n",
        "model_name = \"llama-3.1-8b-instruct.Q4_K_M.gguf\"\n",
        "model_path = f\"/content/{model_name}\"\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Downloading {model_name}...\")\n",
        "    !wget https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf -O {model_path}\n",
        "    print(\"Download complete.\")\n",
        "else:\n",
        "    print(f\"{model_name} already exists.\")\n",
        "\n",
        "# Load quantized Llama model (fastest offline option)\n",
        "model = Llama(\n",
        "    model_path=model_path,\n",
        "    n_gpu_layers=35,      # Use more GPU layers = MUCH FASTER than previous llm\n",
        "    n_ctx=4096,\n",
        "    f16_kv=True,\n",
        "    logits_all=False,\n",
        "    use_mlock=True        # Speed up memory access\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6LIBV4dGAiPq",
      "metadata": {
        "id": "6LIBV4dGAiPq"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Load free embedding model\n",
        "embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Example: your text chunks should be stored in `chunks` list\n",
        "# chunks = [\"text1...\", \"text2...\", ...]\n",
        "\n",
        "print(f\"Total Chunks to Embed: {len(chunks)}\")\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = embedder.encode(chunks, show_progress_bar=True, convert_to_numpy=True)\n",
        "\n",
        "print(\"Embedding shape:\", embeddings.shape)\n",
        "\n",
        "# Save embeddings + chunks\n",
        "output_folder = \"/content/drive/MyDrive/jarvis-ai/embeddings\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "np.save(os.path.join(output_folder, \"chunk_embeddings.npy\"), embeddings)\n",
        "\n",
        "with open(os.path.join(output_folder, \"chunks.json\"), \"w\") as f:\n",
        "    json.dump(chunks, f)\n",
        "\n",
        "print(\"Embeddings + chunk text saved to Google Drive.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TrCTpHp-F6_p",
      "metadata": {
        "id": "TrCTpHp-F6_p"
      },
      "outputs": [],
      "source": [
        "import os, json, numpy as np\n",
        "\n",
        "# importing chunks from google drive.\n",
        "DRIVE_BASE = \"/content/drive/MyDrive/jarvis-ai/embeddings\"\n",
        "chunks_path = os.path.join(DRIVE_BASE, \"chunks.json\")\n",
        "emb_path = os.path.join(DRIVE_BASE, \"chunk_embeddings.npy\")\n",
        "meta_path = os.path.join(DRIVE_BASE, \"metadata.json\")  # optional: if you stored metadata\n",
        "\n",
        "# Load\n",
        "with open(chunks_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    chunks = json.load(f)  # list of strings (chunk texts)\n",
        "\n",
        "embeddings = np.load(emb_path)  # shape: (N, dim)\n",
        "\n",
        "# Optional metadata mapping (source filename, chunk index)\n",
        "metadata = None\n",
        "if os.path.exists(meta_path):\n",
        "    with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        metadata = json.load(f)  # expected list/dict aligned with chunks\n",
        "\n",
        "print(f\"Loaded {len(chunks)} chunks, embeddings shape = {embeddings.shape}\")\n",
        "if metadata:\n",
        "    print(f\"Loaded metadata entries: {len(metadata)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RbEXcBZ-GhIr",
      "metadata": {
        "id": "RbEXcBZ-GhIr"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "\n",
        "# Ensure embeddings are float32\n",
        "emb = embeddings.astype('float32')\n",
        "# Normalize to unit vectors for cosine similarity\n",
        "faiss.normalize_L2(emb)\n",
        "\n",
        "d = emb.shape[1]  # embedding dim\n",
        "\n",
        "# Create index (inner product) and add vectors\n",
        "index = faiss.IndexFlatIP(d)   # inner product on normalized vectors = cosine similarity\n",
        "index.add(emb)\n",
        "print(\"FAISS index ntotal:\", index.ntotal)\n",
        "\n",
        "# Optionally save index to Drive for reuse\n",
        "DRIVE_BASE2 = \"/content/drive/MyDrive/jarvis-ai\"\n",
        "FAISS_INDEX_PATH = os.path.join(DRIVE_BASE2, \"faiss_index.faiss\")\n",
        "faiss.write_index(index, FAISS_INDEX_PATH)\n",
        "print(\"Saved FAISS index to:\", FAISS_INDEX_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rGs5dw56Htaz",
      "metadata": {
        "id": "rGs5dw56Htaz"
      },
      "outputs": [],
      "source": [
        "# to load later\n",
        "# Load index\n",
        "index = faiss.read_index(FAISS_INDEX_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PoWsd_61HxCw",
      "metadata": {
        "id": "PoWsd_61HxCw"
      },
      "outputs": [],
      "source": [
        "# Simple semantic search\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Reuse MiniLM for query embeddings\n",
        "query_embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def semantic_search(query, k=5):\n",
        "    \"\"\"\n",
        "    Returns list of (score, chunk_text, metadata(optional), chunk_id).\n",
        "    Higher score = more similar (cosine).\n",
        "    \"\"\"\n",
        "    q_emb = query_embedder.encode([query], convert_to_numpy=True).astype('float32')\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    D, I = index.search(q_emb, k)  # D: similarities, I: indices\n",
        "    results = []\n",
        "    for score, idx in zip(D[0], I[0]):\n",
        "        if idx < 0:\n",
        "            continue\n",
        "        chunk_text = chunks[idx]\n",
        "        meta = metadata[idx] if (metadata and idx < len(metadata)) else None\n",
        "        results.append({\"score\": float(score), \"chunk_id\": idx, \"text\": chunk_text, \"meta\": meta})\n",
        "    return results\n",
        "\n",
        "# Quick test\n",
        "res = semantic_search(\"Explain Maxwell's equations\", k=3)\n",
        "for r in res:\n",
        "    print(\"score:\", r[\"score\"], \"meta:\", r[\"meta\"])\n",
        "    print(r[\"text\"][:400].replace(\"\\n\",\" \") + \"...\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yt-3DVHtKEHS",
      "metadata": {
        "id": "yt-3DVHtKEHS"
      },
      "outputs": [],
      "source": [
        "# Assembling a RAG prompt.\n",
        "# A naive char-based truncation strategy (safe fallback).\n",
        "def assemble_prompt(question, top_k_results, max_context_chars=3000):\n",
        "    \"\"\"\n",
        "    top_k_results: output of semantic_search\n",
        "    max_context_chars: maximum total characters across all context chunks\n",
        "    \"\"\"\n",
        "    intro = \"You are JARVIS, an expert teaching assistant for engineering. Use the context below to answer the question factually.\\n\\n\"\n",
        "    context = \"\"\n",
        "    chars_used = 0\n",
        "    for r in top_k_results:\n",
        "        chunk = r[\"text\"]\n",
        "        header = f\"[Source: {r['meta'].get('source') if r['meta'] else 'unknown'} | chunk_id: {r['chunk_id']} | score: {r['score']:.3f}]\\n\"\n",
        "        # if adding this chunk will exceed the budget, take a prefix of the chunk\n",
        "        if chars_used + len(chunk) + len(header) > max_context_chars:\n",
        "            remaining = max_context_chars - chars_used - len(header)\n",
        "            if remaining <= 0:\n",
        "                break\n",
        "            chunk = chunk[:remaining]\n",
        "        context += header + chunk + \"\\n\\n\"\n",
        "        chars_used += len(header) + len(chunk)\n",
        "    prompt = intro + \"Context:\\n\" + context + \"\\nQuestion: \" + question + \"\\nAnswer concisely and cite relevant sources in brackets when possible.\"\n",
        "    return prompt\n",
        "\n",
        "# Example\n",
        "top = semantic_search(\"What is a bilinear transfer function?\", k=5)\n",
        "prompt = assemble_prompt(\"Explain bilinear transfer functions and give an example.\", top, max_context_chars=3000)\n",
        "print(prompt[:1500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iw3Xq3SoNbqz",
      "metadata": {
        "id": "iw3Xq3SoNbqz"
      },
      "outputs": [],
      "source": [
        "# Example using llama-cpp-python (adjust model_path to your GGUF file)\n",
        "from llama_cpp import Llama\n",
        "import os\n",
        "\n",
        "# Path to your GGUF model file (put the model file into Drive and use the path)\n",
        "MODEL_PATH = model_path #\"/content/drive/MyDrive/JARVIS_MODELS/mistral-7b-instruct.gguf\"  # change to your model file\n",
        "\n",
        "def call_local_llm(prompt, max_tokens=512, temperature=0.1):\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        # Fallback: return the prompt for inspection\n",
        "        return {\"error\": \"Model not found\", \"prompt\": prompt}\n",
        "    # Initialize the model (you could keep a global model object to avoid reloading)\n",
        "    model = Llama(model_path=MODEL_PATH, n_ctx=4096)\n",
        "    out = model(prompt, max_tokens=max_tokens, temperature=temperature)\n",
        "    # The llama-cpp-python response has 'choices' etc; we return text\n",
        "    text = out['choices'][0]['text']\n",
        "    return {\"text\": text, \"raw\": out}\n",
        "\n",
        "# Usage\n",
        "out = call_local_llm(prompt, max_tokens=400)\n",
        "if 'text' in out:\n",
        "    print(out['text'][:1500])\n",
        "else:\n",
        "    print(\"No model available. Inspect prompt:\\n\", out['prompt'][:1200])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yjm9WjaHRFNV",
      "metadata": {
        "id": "Yjm9WjaHRFNV"
      },
      "outputs": [],
      "source": [
        "def answer_question(query, k=6, max_context_chars=3000, max_tokens=400, temperature=0.1):\n",
        "    # 1) retrieve\n",
        "    top = semantic_search(query, k=k)\n",
        "    # 2) assemble\n",
        "    prompt = assemble_prompt(query, top, max_context_chars=max_context_chars)\n",
        "    # 3) call LLM\n",
        "    result = call_local_llm(prompt, max_tokens=max_tokens, temperature=temperature)\n",
        "    # 4) return everything useful\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"prompt\": prompt,\n",
        "        \"retrieved\": top,\n",
        "        \"response\": result\n",
        "    }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aYz2UNAmUKH0",
      "metadata": {
        "id": "aYz2UNAmUKH0"
      },
      "outputs": [],
      "source": [
        "# Example (inspect output)\n",
        "res = answer_question(\"What is a 3phase transformer?\", k=5)\n",
        "if 'text' in res['response']:\n",
        "    print(\"LLM answer (truncated):\\n\", res['response']['text'][:1200])\n",
        "else:\n",
        "    print(\"Model didn't run; prompt to inspect:\\n\", res['prompt'][:1200])\n",
        "#will add fine tuning soon"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}