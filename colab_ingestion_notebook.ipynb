{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Storm00212/JARVIS/blob/main/colab_ingestion_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "930bb34e",
      "metadata": {
        "id": "930bb34e"
      },
      "source": [
        "\n",
        "# JARVIS RAG Ingestion Notebook (Colab-ready)\n",
        "\n",
        "**Purpose:** This notebook walks you through an end-to-end prototype ingestion pipeline that:\n",
        "- Accepts PDF / DOCX / PPTX documents\n",
        "- Extracts clean text (with optional OCR)\n",
        "- Splits documents into semantic chunks\n",
        "- Generates embeddings for chunks\n",
        "- Stores chunks + embeddings into a local Chroma vector store\n",
        "- Exposes a simple `ask(question)` function that uses retrieval + prompt assembly (RAG)\n",
        "\n",
        "**Notes & assumptions**\n",
        "- Designed for Google Colab interactive use.\n",
        "- Includes a sample path from this session: `/mnt/data/jarvis-ai.zip` which you can inspect or replace with your own uploads.\n",
        "- Each code cell includes detailed comments to help you follow along.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b7dd3208",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7dd3208",
        "outputId": "ed1e5edc-de73-4e5b-d6c9-a5a95e220b3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Dependencies installed (or already present).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# SECTION 1: Install required packages\n",
        "# Run this cell in Google Colab to install dependencies. It may take 1-2 minutes.\n",
        "!pip install --quiet pypdf python-docx python-pptx sentence-transformers chromadb langchain tiktoken PyMuPDF langchain_text_splitters faiss-cpu llama-cpp-python\n",
        "print('Dependencies installed (or already present).')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdb1df0a",
      "metadata": {
        "id": "cdb1df0a"
      },
      "source": [
        "\n",
        "## SECTION 2: Upload files (use UI) or use sample path\n",
        "\n",
        "You can upload files interactively using the cell below, or skip upload and use the sample file `'/mnt/data/jarvis-ai.zip'` if present.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6ERR0AEhhA6",
        "outputId": "4dc7b2af-819c-489c-f173-e3dd37b463ce"
      },
      "id": "o6ERR0AEhhA6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up the directory to upload the files\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/jarvis-ai\"\n",
        "RAW_DATA_DIR = f\"{BASE_DIR}/data/raw\"\n",
        "\n",
        "# Create folders if they don't exist\n",
        "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Base project folder:\", BASE_DIR)\n",
        "print(\"Raw data folder:\", RAW_DATA_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvxHIzeqiCkB",
        "outputId": "6fb62c36-e57b-4cc1-ae67-639806c070a4"
      },
      "id": "IvxHIzeqiCkB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base project folder: /content/drive/MyDrive/jarvis-ai\n",
            "Raw data folder: /content/drive/MyDrive/jarvis-ai/data/raw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uploading files to directory\n",
        "from google.colab import files\n",
        "import shutil # Import shutil for cross-device moves\n",
        "\n",
        "uploaded_files = files.upload()  # choose multiple files\n",
        "\n",
        "\n",
        "# Move uploaded files into the Drive folder\n",
        "for filename in uploaded_files.keys():\n",
        "    src = f\"/content/{filename}\"\n",
        "    dst = f\"{RAW_DATA_DIR}/{filename}\"\n",
        "    print(f\"Moving {src} → {dst}\")\n",
        "    # Use shutil.move to handle cross-device links (copy then delete)\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "print(\"\\nUpload complete!\")\n",
        "\n",
        "print(\"Files in your study notes folder:\")\n",
        "print(os.listdir(RAW_DATA_DIR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HD04XWpniZKa",
        "outputId": "77e95722-aa07-4cbd-e097-b2fe39311882"
      },
      "id": "HD04XWpniZKa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a5ede0cb-1554-486f-9b95-a48d26d3757b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a5ede0cb-1554-486f-9b95-a48d26d3757b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1. Amplifiers with Negative Feedback.pdf to 1. Amplifiers with Negative Feedback (2).pdf\n",
            "Saving 3.1 Resources .pdf to 3.1 Resources  (2).pdf\n",
            "Saving 3.2 Past Papers  .pdf to 3.2 Past Papers   (2).pdf\n",
            "Saving A textbook of Electrical Technology B. L. Thereja All Volumes ( PDFDrive.pdf to A textbook of Electrical Technology B. L. Thereja All Volumes ( PDFDrive (2).pdf\n",
            "Saving applied-numerical-methods-with-matlab-for-engineers-and-scientists-4nbsped-0073397962-9780073397962_compress.pdf to applied-numerical-methods-with-matlab-for-engineers-and-scientists-4nbsped-0073397962-9780073397962_compress (2).pdf\n",
            "Saving assignment_1.pdf to assignment_1 (2).pdf\n",
            "Saving churchillbrown.pdf to churchillbrown (2).pdf\n",
            "Saving Complex analysis Q&A.pdf to Complex analysis Q&A (2).pdf\n",
            "Saving Complex analysis Q&A2.pdf to Complex analysis Q&A2 (2).pdf\n",
            "Saving Design_of_Analog_Filters_Rolf_Schaumann.pdf to Design_of_Analog_Filters_Rolf_Schaumann (2).pdf\n",
            "Saving digielec.pdf to digielec (2).pdf\n",
            "Saving DOC-20250827-WA0009..pdf to DOC-20250827-WA0009. (2).pdf\n",
            "Saving DOC-20250908-WA0053..pdf to DOC-20250908-WA0053. (2).pdf\n",
            "Saving Document from ..pdf to Document from . (2).pdf\n",
            "Saving EEE 2206_EET 2204_Electromagnetics I_Exam.pdf to EEE 2206_EET 2204_Electromagnetics I_Exam (2).pdf\n",
            "Saving EEE 2305 - Electromagnetics I - Exam - 2017-18 sem I (2).pdf to EEE 2305 - Electromagnetics I - Exam - 2017-18 sem I (2) (2).pdf\n",
            "Saving EEE 3101_Analogue Electronics_Exam.pdf to EEE 3101_Analogue Electronics_Exam (2).pdf\n",
            "Saving EEE 3101cbd_ANALOGUE ELECTRONICS I EXAM 2019-2020.pdf to EEE 3101cbd_ANALOGUE ELECTRONICS I EXAM 2019-2020 (2).pdf\n",
            "Saving EEE 3103 ELECTROMAGNETICS II.pdf to EEE 3103 ELECTROMAGNETICS II (2).pdf\n",
            "Saving EEE 3207 ELECTRICAL MACHINES 2.pptx to EEE 3207 ELECTRICAL MACHINES 2 (2).pptx\n",
            "Saving EEE 3208 ELECTROMAGNETICS III lec1 notes.pdf to EEE 3208 ELECTROMAGNETICS III lec1 notes (2).pdf\n",
            "Saving EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (1).pdf to EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (1) (2).pdf\n",
            "Saving EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes.pdf to EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (3).pdf\n",
            "Saving eee.eti.3104.cat.ii.make_up.ms.pdf to eee.eti.3104.cat.ii.make_up.ms (2).pdf\n",
            "Saving eee.eti.3104.model.solutions.cat.ii.pdf to eee.eti.3104.model.solutions.cat.ii (2).pdf\n",
            "Saving EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 ready.pdf to EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 ready (2).pdf\n",
            "Saving EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1.pdf to EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 (2).pdf\n",
            "Saving EEE_ETI3105_Assignment ONE.pdf to EEE_ETI3105_Assignment ONE (2).pdf\n",
            "Saving EEE_ETI3105_CAT 2.pdf to EEE_ETI3105_CAT 2 (2).pdf\n",
            "Saving EEE2205 Electromagnetics I ready.pdf to EEE2205 Electromagnetics I ready (2).pdf\n",
            "Saving EEE2205 Electromagnetics I.pdf to EEE2205 Electromagnetics I (2).pdf\n",
            "Saving EEE2206cbd ELECTROMAGNETICS I.pdf to EEE2206cbd ELECTROMAGNETICS I (2).pdf\n",
            "Saving eee3102 [1-20].pdf to eee3102 [1-20] (2).pdf\n",
            "Saving eee3102 [21-33].pdf to eee3102 [21-33] (2).pdf\n",
            "Saving eee3102 [49-67].pdf to eee3102 [49-67] (2).pdf\n",
            "Saving eee3104eti3104 [1-68].pdf to eee3104eti3104 [1-68] (2).pdf\n",
            "Saving eee3104eti3104.pdf to eee3104eti3104 (2).pdf\n",
            "Saving elecmag-i-electromagnetics....pdf to elecmag-i-electromagnetics... (2).pdf\n",
            "Saving Electromagnetic_Field_Theory_U_A_Bakshi. - By EasyEngineering.net.pdf to Electromagnetic_Field_Theory_U_A_Bakshi. - By EasyEngineering.net (2).pdf\n",
            "Saving Electromagnetics.pdf to Electromagnetics (2).pdf\n",
            "Saving Electronics Fundamentals Circuits Devices and Applications 8th Edition By David M Buchla and Thomas L Floyd.pdf to Electronics Fundamentals Circuits Devices and Applications 8th Edition By David M Buchla and Thomas L Floyd (2).pdf\n",
            "Saving guru_b-s-_hiziroglu_h-r-_electromagnetic_field_bookzz-org.pdf to guru_b-s-_hiziroglu_h-r-_electromagnetic_field_bookzz-org (2).pdf\n",
            "Saving Lecture 1_BJT Configurations & Their Characteristics.pdf to Lecture 1_BJT Configurations & Their Characteristics (2).pdf\n",
            "Saving LECTURE 1-MAGNETIC CIRCUITS.pdf to LECTURE 1-MAGNETIC CIRCUITS (2).pdf\n",
            "Saving Lecture 2_Large Signal Amplifiers_1 of 2.pdf to Lecture 2_Large Signal Amplifiers_1 of 2 (2).pdf\n",
            "Saving LECTURE 2-TRANSFORMERS.pdf to LECTURE 2-TRANSFORMERS (2).pdf\n",
            "Saving Lecture 3_Large Signal Amplifiers_2 of 2.pdf to Lecture 3_Large Signal Amplifiers_2 of 2 (2).pdf\n",
            "Saving LECTURE 3-PRACTICAL TRANSFORMERS.pdf to LECTURE 3-PRACTICAL TRANSFORMERS (2).pdf\n",
            "Saving LECTURE 4-EQUIVALENT CIRCUITS_TRANSFORMERS .pdf to LECTURE 4-EQUIVALENT CIRCUITS_TRANSFORMERS  (2).pdf\n",
            "Saving Lecture 05_Three Phase AC circuits.pdf to Lecture 05_Three Phase AC circuits (2).pdf\n",
            "Saving LECTURE 5-TRANSFORMER TESTS & EFFICIENCY.pdf to LECTURE 5-TRANSFORMER TESTS & EFFICIENCY (2).pdf\n",
            "Saving LECTURE 6-DC MACHINE FUNDAMENTALS.pdf to LECTURE 6-DC MACHINE FUNDAMENTALS (2).pdf\n",
            "Saving Lecture 7-Filters.pdf to Lecture 7-Filters (2).pdf\n",
            "Saving LECTURE 7-TYPES OF DC GENERATORS.pdf to LECTURE 7-TYPES OF DC GENERATORS (2).pdf\n",
            "Saving LECTURE 8-DC MOTORS.pdf to LECTURE 8-DC MOTORS (2).pdf\n",
            "Saving Lecture 8-Laplace Transform.pdf to Lecture 8-Laplace Transform (2).pdf\n",
            "Saving MAGNETIC FLUX DENSITY.pdf to MAGNETIC FLUX DENSITY (2).pdf\n",
            "Saving model.solutions.pdf to model.solutions (2).pdf\n",
            "Saving Numerical-Methods-Rao-V.-Dukkipati-2010.pdf to Numerical-Methods-Rao-V.-Dukkipati-2010 (2).pdf\n",
            "Saving Q1to4.pdf to Q1to4 (2).pdf\n",
            "Saving Q5.pdf to Q5 (2).pdf\n",
            "Saving Sadiqu.pdf to Sadiqu (2).pdf\n",
            "Saving SMA 3121 Topic 4 Cauchy formular (1).pdf to SMA 3121 Topic 4 Cauchy formular (1) (2).pdf\n",
            "Saving SMA 3121 Topic 7 Laurent series (1).pdf to SMA 3121 Topic 7 Laurent series (1) (2).pdf\n",
            "Saving SMA 3121 Topic 9 Using Residue (1).pdf to SMA 3121 Topic 9 Using Residue (1) (2).pdf\n",
            "Saving SMA 3121 Topic 10 Conformal (1).pdf to SMA 3121 Topic 10 Conformal (1) (2).pdf\n",
            "Saving Topic 2_Small Signal Amplifiers.pdf to Topic 2_Small Signal Amplifiers (2).pdf\n",
            "Saving Topic 3_Bipolar Junction Transistors (2).pdf to Topic 3_Bipolar Junction Transistors (2) (2).pdf\n",
            "Saving Topic 3_Multistage Transistor Amplifiers.pdf to Topic 3_Multistage Transistor Amplifiers (2).pdf\n",
            "Saving Topic 3_Single Stage Transistor Amplifiers (1).pdf to Topic 3_Single Stage Transistor Amplifiers (1) (2).pdf\n",
            "Saving Topic 3_Single Stage Transistor Amplifiers.pdf to Topic 3_Single Stage Transistor Amplifiers (3).pdf\n",
            "Saving Topic 4_MOSFETS.pdf to Topic 4_MOSFETS (2).pdf\n",
            "Saving V.K-Mehta-Principles-of-Electronics.pdf to V.K-Mehta-Principles-of-Electronics (2).pdf\n",
            "Moving /content/1. Amplifiers with Negative Feedback (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/1. Amplifiers with Negative Feedback (2).pdf\n",
            "Moving /content/3.1 Resources  (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/3.1 Resources  (2).pdf\n",
            "Moving /content/3.2 Past Papers   (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/3.2 Past Papers   (2).pdf\n",
            "Moving /content/A textbook of Electrical Technology B. L. Thereja All Volumes ( PDFDrive (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/A textbook of Electrical Technology B. L. Thereja All Volumes ( PDFDrive (2).pdf\n",
            "Moving /content/applied-numerical-methods-with-matlab-for-engineers-and-scientists-4nbsped-0073397962-9780073397962_compress (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/applied-numerical-methods-with-matlab-for-engineers-and-scientists-4nbsped-0073397962-9780073397962_compress (2).pdf\n",
            "Moving /content/assignment_1 (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/assignment_1 (2).pdf\n",
            "Moving /content/churchillbrown (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/churchillbrown (2).pdf\n",
            "Moving /content/Complex analysis Q&A (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Complex analysis Q&A (2).pdf\n",
            "Moving /content/Complex analysis Q&A2 (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Complex analysis Q&A2 (2).pdf\n",
            "Moving /content/Design_of_Analog_Filters_Rolf_Schaumann (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Design_of_Analog_Filters_Rolf_Schaumann (2).pdf\n",
            "Moving /content/digielec (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/digielec (2).pdf\n",
            "Moving /content/DOC-20250827-WA0009. (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/DOC-20250827-WA0009. (2).pdf\n",
            "Moving /content/DOC-20250908-WA0053. (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/DOC-20250908-WA0053. (2).pdf\n",
            "Moving /content/Document from . (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Document from . (2).pdf\n",
            "Moving /content/EEE 2206_EET 2204_Electromagnetics I_Exam (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE 2206_EET 2204_Electromagnetics I_Exam (2).pdf\n",
            "Moving /content/EEE 2305 - Electromagnetics I - Exam - 2017-18 sem I (2) (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE 2305 - Electromagnetics I - Exam - 2017-18 sem I (2) (2).pdf\n",
            "Moving /content/EEE 3101_Analogue Electronics_Exam (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE 3101_Analogue Electronics_Exam (2).pdf\n",
            "Moving /content/EEE 3101cbd_ANALOGUE ELECTRONICS I EXAM 2019-2020 (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE 3101cbd_ANALOGUE ELECTRONICS I EXAM 2019-2020 (2).pdf\n",
            "Moving /content/EEE 3103 ELECTROMAGNETICS II (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE 3103 ELECTROMAGNETICS II (2).pdf\n",
            "Moving /content/EEE 3207 ELECTRICAL MACHINES 2 (2).pptx → /content/drive/MyDrive/jarvis-ai/data/raw/EEE 3207 ELECTRICAL MACHINES 2 (2).pptx\n",
            "Moving /content/EEE 3208 ELECTROMAGNETICS III lec1 notes (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE 3208 ELECTROMAGNETICS III lec1 notes (2).pdf\n",
            "Moving /content/EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (1) (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (1) (2).pdf\n",
            "Moving /content/EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (3).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (3).pdf\n",
            "Moving /content/eee.eti.3104.cat.ii.make_up.ms (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/eee.eti.3104.cat.ii.make_up.ms (2).pdf\n",
            "Moving /content/eee.eti.3104.model.solutions.cat.ii (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/eee.eti.3104.model.solutions.cat.ii (2).pdf\n",
            "Moving /content/EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 ready (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 ready (2).pdf\n",
            "Moving /content/EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 (2).pdf\n",
            "Moving /content/EEE_ETI3105_Assignment ONE (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE_ETI3105_Assignment ONE (2).pdf\n",
            "Moving /content/EEE_ETI3105_CAT 2 (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE_ETI3105_CAT 2 (2).pdf\n",
            "Moving /content/EEE2205 Electromagnetics I ready (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE2205 Electromagnetics I ready (2).pdf\n",
            "Moving /content/EEE2205 Electromagnetics I (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE2205 Electromagnetics I (2).pdf\n",
            "Moving /content/EEE2206cbd ELECTROMAGNETICS I (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/EEE2206cbd ELECTROMAGNETICS I (2).pdf\n",
            "Moving /content/eee3102 [1-20] (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/eee3102 [1-20] (2).pdf\n",
            "Moving /content/eee3102 [21-33] (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/eee3102 [21-33] (2).pdf\n",
            "Moving /content/eee3102 [49-67] (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/eee3102 [49-67] (2).pdf\n",
            "Moving /content/eee3104eti3104 [1-68] (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/eee3104eti3104 [1-68] (2).pdf\n",
            "Moving /content/eee3104eti3104 (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/eee3104eti3104 (2).pdf\n",
            "Moving /content/elecmag-i-electromagnetics... (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/elecmag-i-electromagnetics... (2).pdf\n",
            "Moving /content/Electromagnetic_Field_Theory_U_A_Bakshi. - By EasyEngineering.net (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Electromagnetic_Field_Theory_U_A_Bakshi. - By EasyEngineering.net (2).pdf\n",
            "Moving /content/Electromagnetics (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Electromagnetics (2).pdf\n",
            "Moving /content/Electronics Fundamentals Circuits Devices and Applications 8th Edition By David M Buchla and Thomas L Floyd (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Electronics Fundamentals Circuits Devices and Applications 8th Edition By David M Buchla and Thomas L Floyd (2).pdf\n",
            "Moving /content/guru_b-s-_hiziroglu_h-r-_electromagnetic_field_bookzz-org (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/guru_b-s-_hiziroglu_h-r-_electromagnetic_field_bookzz-org (2).pdf\n",
            "Moving /content/Lecture 1_BJT Configurations & Their Characteristics (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Lecture 1_BJT Configurations & Their Characteristics (2).pdf\n",
            "Moving /content/LECTURE 1-MAGNETIC CIRCUITS (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/LECTURE 1-MAGNETIC CIRCUITS (2).pdf\n",
            "Moving /content/Lecture 2_Large Signal Amplifiers_1 of 2 (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Lecture 2_Large Signal Amplifiers_1 of 2 (2).pdf\n",
            "Moving /content/LECTURE 2-TRANSFORMERS (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/LECTURE 2-TRANSFORMERS (2).pdf\n",
            "Moving /content/Lecture 3_Large Signal Amplifiers_2 of 2 (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Lecture 3_Large Signal Amplifiers_2 of 2 (2).pdf\n",
            "Moving /content/LECTURE 3-PRACTICAL TRANSFORMERS (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/LECTURE 3-PRACTICAL TRANSFORMERS (2).pdf\n",
            "Moving /content/LECTURE 4-EQUIVALENT CIRCUITS_TRANSFORMERS  (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/LECTURE 4-EQUIVALENT CIRCUITS_TRANSFORMERS  (2).pdf\n",
            "Moving /content/Lecture 05_Three Phase AC circuits (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Lecture 05_Three Phase AC circuits (2).pdf\n",
            "Moving /content/LECTURE 5-TRANSFORMER TESTS & EFFICIENCY (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/LECTURE 5-TRANSFORMER TESTS & EFFICIENCY (2).pdf\n",
            "Moving /content/LECTURE 6-DC MACHINE FUNDAMENTALS (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/LECTURE 6-DC MACHINE FUNDAMENTALS (2).pdf\n",
            "Moving /content/Lecture 7-Filters (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Lecture 7-Filters (2).pdf\n",
            "Moving /content/LECTURE 7-TYPES OF DC GENERATORS (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/LECTURE 7-TYPES OF DC GENERATORS (2).pdf\n",
            "Moving /content/LECTURE 8-DC MOTORS (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/LECTURE 8-DC MOTORS (2).pdf\n",
            "Moving /content/Lecture 8-Laplace Transform (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Lecture 8-Laplace Transform (2).pdf\n",
            "Moving /content/MAGNETIC FLUX DENSITY (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/MAGNETIC FLUX DENSITY (2).pdf\n",
            "Moving /content/model.solutions (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/model.solutions (2).pdf\n",
            "Moving /content/Numerical-Methods-Rao-V.-Dukkipati-2010 (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Numerical-Methods-Rao-V.-Dukkipati-2010 (2).pdf\n",
            "Moving /content/Q1to4 (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Q1to4 (2).pdf\n",
            "Moving /content/Q5 (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Q5 (2).pdf\n",
            "Moving /content/Sadiqu (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Sadiqu (2).pdf\n",
            "Moving /content/SMA 3121 Topic 4 Cauchy formular (1) (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/SMA 3121 Topic 4 Cauchy formular (1) (2).pdf\n",
            "Moving /content/SMA 3121 Topic 7 Laurent series (1) (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/SMA 3121 Topic 7 Laurent series (1) (2).pdf\n",
            "Moving /content/SMA 3121 Topic 9 Using Residue (1) (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/SMA 3121 Topic 9 Using Residue (1) (2).pdf\n",
            "Moving /content/SMA 3121 Topic 10 Conformal (1) (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/SMA 3121 Topic 10 Conformal (1) (2).pdf\n",
            "Moving /content/Topic 2_Small Signal Amplifiers (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Topic 2_Small Signal Amplifiers (2).pdf\n",
            "Moving /content/Topic 3_Bipolar Junction Transistors (2) (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Topic 3_Bipolar Junction Transistors (2) (2).pdf\n",
            "Moving /content/Topic 3_Multistage Transistor Amplifiers (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Topic 3_Multistage Transistor Amplifiers (2).pdf\n",
            "Moving /content/Topic 3_Single Stage Transistor Amplifiers (1) (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Topic 3_Single Stage Transistor Amplifiers (1) (2).pdf\n",
            "Moving /content/Topic 3_Single Stage Transistor Amplifiers (3).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Topic 3_Single Stage Transistor Amplifiers (3).pdf\n",
            "Moving /content/Topic 4_MOSFETS (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/Topic 4_MOSFETS (2).pdf\n",
            "Moving /content/V.K-Mehta-Principles-of-Electronics (2).pdf → /content/drive/MyDrive/jarvis-ai/data/raw/V.K-Mehta-Principles-of-Electronics (2).pdf\n",
            "\n",
            "Upload complete!\n",
            "Files in your study notes folder:\n",
            "['1. Amplifiers with Negative Feedback (2).pdf', '3.1 Resources  (2).pdf', '3.2 Past Papers   (2).pdf', 'A textbook of Electrical Technology B. L. Thereja All Volumes ( PDFDrive (2).pdf', 'applied-numerical-methods-with-matlab-for-engineers-and-scientists-4nbsped-0073397962-9780073397962_compress (2).pdf', 'assignment_1 (2).pdf', 'churchillbrown (2).pdf', 'Complex analysis Q&A (2).pdf', 'Complex analysis Q&A2 (2).pdf', 'Design_of_Analog_Filters_Rolf_Schaumann (2).pdf', 'digielec (2).pdf', 'DOC-20250827-WA0009. (2).pdf', 'DOC-20250908-WA0053. (2).pdf', 'Document from . (2).pdf', 'EEE 2206_EET 2204_Electromagnetics I_Exam (2).pdf', 'EEE 2305 - Electromagnetics I - Exam - 2017-18 sem I (2) (2).pdf', 'EEE 3101_Analogue Electronics_Exam (2).pdf', 'EEE 3101cbd_ANALOGUE ELECTRONICS I EXAM 2019-2020 (2).pdf', 'EEE 3103 ELECTROMAGNETICS II (2).pdf', 'EEE 3207 ELECTRICAL MACHINES 2 (2).pptx', 'EEE 3208 ELECTROMAGNETICS III lec1 notes (2).pdf', 'EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (1) (2).pdf', 'EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (3).pdf', 'eee.eti.3104.cat.ii.make_up.ms (2).pdf', 'eee.eti.3104.model.solutions.cat.ii (2).pdf', 'EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 ready (2).pdf', 'EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 (2).pdf', 'EEE_ETI3105_Assignment ONE (2).pdf', 'EEE_ETI3105_CAT 2 (2).pdf', 'EEE2205 Electromagnetics I ready (2).pdf', 'EEE2205 Electromagnetics I (2).pdf', 'EEE2206cbd ELECTROMAGNETICS I (2).pdf', 'eee3102 [1-20] (2).pdf', 'eee3102 [21-33] (2).pdf', 'eee3102 [49-67] (2).pdf', 'eee3104eti3104 [1-68] (2).pdf', 'eee3104eti3104 (2).pdf', 'elecmag-i-electromagnetics... (2).pdf', 'Electromagnetic_Field_Theory_U_A_Bakshi. - By EasyEngineering.net (2).pdf', 'Electromagnetics (2).pdf', 'Electronics Fundamentals Circuits Devices and Applications 8th Edition By David M Buchla and Thomas L Floyd (2).pdf', 'guru_b-s-_hiziroglu_h-r-_electromagnetic_field_bookzz-org (2).pdf', 'Lecture 1_BJT Configurations & Their Characteristics (2).pdf', 'LECTURE 1-MAGNETIC CIRCUITS (2).pdf', 'Lecture 2_Large Signal Amplifiers_1 of 2 (2).pdf', 'LECTURE 2-TRANSFORMERS (2).pdf', 'Lecture 3_Large Signal Amplifiers_2 of 2 (2).pdf', 'LECTURE 3-PRACTICAL TRANSFORMERS (2).pdf', 'LECTURE 4-EQUIVALENT CIRCUITS_TRANSFORMERS  (2).pdf', 'Lecture 05_Three Phase AC circuits (2).pdf', 'LECTURE 5-TRANSFORMER TESTS & EFFICIENCY (2).pdf', 'LECTURE 6-DC MACHINE FUNDAMENTALS (2).pdf', 'Lecture 7-Filters (2).pdf', 'LECTURE 7-TYPES OF DC GENERATORS (2).pdf', 'LECTURE 8-DC MOTORS (2).pdf', 'Lecture 8-Laplace Transform (2).pdf', 'MAGNETIC FLUX DENSITY (2).pdf', 'model.solutions (2).pdf', 'Numerical-Methods-Rao-V.-Dukkipati-2010 (2).pdf', 'Q1to4 (2).pdf', 'Q5 (2).pdf', 'Sadiqu (2).pdf', 'SMA 3121 Topic 4 Cauchy formular (1) (2).pdf', 'SMA 3121 Topic 7 Laurent series (1) (2).pdf', 'SMA 3121 Topic 9 Using Residue (1) (2).pdf', 'SMA 3121 Topic 10 Conformal (1) (2).pdf', 'Topic 2_Small Signal Amplifiers (2).pdf', 'Topic 3_Bipolar Junction Transistors (2) (2).pdf', 'Topic 3_Multistage Transistor Amplifiers (2).pdf', 'Topic 3_Single Stage Transistor Amplifiers (1) (2).pdf', 'Topic 3_Single Stage Transistor Amplifiers (3).pdf', 'Topic 4_MOSFETS (2).pdf', 'V.K-Mehta-Principles-of-Electronics (2).pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading the pdfs from my drive"
      ],
      "metadata": {
        "id": "Qn_1KJIyiqQv"
      },
      "id": "Qn_1KJIyiqQv"
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1 — Load PDFs from Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import fitz  # PyMuPDF for PDFs\n",
        "import docx  # DOCX reader\n",
        "from pptx import Presentation  # PPTX reader\n",
        "\n",
        "# CHANGE THIS to your folder\n",
        "DATA_FOLDER = \"/content/drive/MyDrive/jarvis-ai/data/raw\"\n",
        "\n",
        "documents = {}  # filename → extracted text\n",
        "\n",
        "\n",
        "# function to read docx\n",
        "def extract_docx(path):\n",
        "    doc = docx.Document(path)\n",
        "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "    return text\n",
        "\n",
        "\n",
        "# function to read pptx\n",
        "def extract_pptx(path):\n",
        "    prs = Presentation(path)\n",
        "    text = []\n",
        "\n",
        "    for slide in prs.slides:\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text\"):\n",
        "                text.append(shape.text)\n",
        "\n",
        "    return \"\\n\".join(text)\n",
        "\n",
        "\n",
        "# function to read pdf\n",
        "def extract_pdf(path):\n",
        "    doc = fitz.open(path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text(\"text\")\n",
        "    return text\n",
        "\n",
        "\n",
        "# iterate through the study notes folder\n",
        "for filename in os.listdir(DATA_FOLDER):\n",
        "    path = os.path.join(DATA_FOLDER, filename)\n",
        "\n",
        "    if filename.lower().endswith(\".pdf\"):\n",
        "        print(f\"Extracting PDF: {filename}\")\n",
        "        documents[filename] = extract_pdf(path)\n",
        "\n",
        "    elif filename.lower().endswith(\".docx\"):\n",
        "        print(f\"Extracting DOCX: {filename}\")\n",
        "        documents[filename] = extract_docx(path)\n",
        "\n",
        "    elif filename.lower().endswith(\".pptx\"):\n",
        "        print(f\"Extracting PPTX: {filename}\")\n",
        "        documents[filename] = extract_pptx(path)\n",
        "\n",
        "    else:\n",
        "        print(f\"Skipping unsupported file: {filename}\")\n",
        "\n",
        "\n",
        "print(\"\\n✔ Extraction complete!\")\n",
        "print(f\"Total loaded documents: {len(documents)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuR54l3FiuiA",
        "outputId": "0eaa511e-11a7-4e92-a31a-8fe72ca67d4b"
      },
      "id": "tuR54l3FiuiA",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracting PDF: 1. Amplifiers with Negative Feedback (2).pdf\n",
            "Extracting PDF: 3.1 Resources  (2).pdf\n",
            "Extracting PDF: churchillbrown (2).pdf\n",
            "Extracting PDF: EEE 3208 ELECTROMAGNETICS III lec1 notes (2).pdf\n",
            "Extracting PDF: eee.eti.3104.cat.ii.make_up.ms (2).pdf\n",
            "Extracting PDF: eee3102 [1-20] (2).pdf\n",
            "Extracting PDF: EEE 2206_EET 2204_Electromagnetics I_Exam (2).pdf\n",
            "Extracting PDF: eee3102 [21-33] (2).pdf\n",
            "Extracting PDF: EEE_ETI3105_Assignment ONE (2).pdf\n",
            "Extracting PDF: Design_of_Analog_Filters_Rolf_Schaumann (2).pdf\n",
            "Extracting PDF: digielec (2).pdf\n",
            "Extracting PDF: EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (3).pdf\n",
            "Extracting PDF: eee3104eti3104 [1-68] (2).pdf\n",
            "Extracting PDF: Electromagnetics (2).pdf\n",
            "Extracting PDF: A textbook of Electrical Technology B. L. Thereja All Volumes ( PDFDrive (2).pdf\n",
            "Extracting PDF: EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 (2).pdf\n",
            "Extracting PDF: EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (1) (2).pdf\n",
            "Extracting PDF: EEE2205 Electromagnetics I (2).pdf\n",
            "Extracting PDF: 3.2 Past Papers   (2).pdf\n",
            "Extracting PPTX: EEE 3207 ELECTRICAL MACHINES 2 (2).pptx\n",
            "Extracting PDF: Complex analysis Q&A (2).pdf\n",
            "Extracting PDF: eee3102 [49-67] (2).pdf\n",
            "Extracting PDF: EEE 3101_Analogue Electronics_Exam (2).pdf\n",
            "Extracting PDF: EEE_ETI3105_CAT 2 (2).pdf\n",
            "Extracting PDF: DOC-20250908-WA0053. (2).pdf\n",
            "Extracting PDF: EEE2206cbd ELECTROMAGNETICS I (2).pdf\n",
            "Extracting PDF: DOC-20250827-WA0009. (2).pdf\n",
            "Extracting PDF: Complex analysis Q&A2 (2).pdf\n",
            "Extracting PDF: EEE2205 Electromagnetics I ready (2).pdf\n",
            "Extracting PDF: Electromagnetic_Field_Theory_U_A_Bakshi. - By EasyEngineering.net (2).pdf\n",
            "Extracting PDF: Electronics Fundamentals Circuits Devices and Applications 8th Edition By David M Buchla and Thomas L Floyd (2).pdf\n",
            "Extracting PDF: assignment_1 (2).pdf\n",
            "Extracting PDF: EEE 2305 - Electromagnetics I - Exam - 2017-18 sem I (2) (2).pdf\n",
            "Extracting PDF: eee.eti.3104.model.solutions.cat.ii (2).pdf\n",
            "Extracting PDF: Document from . (2).pdf\n",
            "Extracting PDF: applied-numerical-methods-with-matlab-for-engineers-and-scientists-4nbsped-0073397962-9780073397962_compress (2).pdf\n",
            "Extracting PDF: EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 ready (2).pdf\n",
            "Extracting PDF: eee3104eti3104 (2).pdf\n",
            "Extracting PDF: elecmag-i-electromagnetics... (2).pdf\n",
            "Extracting PDF: EEE 3101cbd_ANALOGUE ELECTRONICS I EXAM 2019-2020 (2).pdf\n",
            "Extracting PDF: EEE 3103 ELECTROMAGNETICS II (2).pdf\n",
            "Extracting PDF: guru_b-s-_hiziroglu_h-r-_electromagnetic_field_bookzz-org (2).pdf\n",
            "Extracting PDF: Lecture 1_BJT Configurations & Their Characteristics (2).pdf\n",
            "Extracting PDF: Lecture 8-Laplace Transform (2).pdf\n",
            "Extracting PDF: LECTURE 5-TRANSFORMER TESTS & EFFICIENCY (2).pdf\n",
            "Extracting PDF: Numerical-Methods-Rao-V.-Dukkipati-2010 (2).pdf\n",
            "Extracting PDF: Sadiqu (2).pdf\n",
            "Extracting PDF: LECTURE 8-DC MOTORS (2).pdf\n",
            "Extracting PDF: Topic 3_Single Stage Transistor Amplifiers (1) (2).pdf\n",
            "Extracting PDF: LECTURE 7-TYPES OF DC GENERATORS (2).pdf\n",
            "Extracting PDF: Topic 4_MOSFETS (2).pdf\n",
            "Extracting PDF: Topic 2_Small Signal Amplifiers (2).pdf\n",
            "Extracting PDF: SMA 3121 Topic 10 Conformal (1) (2).pdf\n",
            "Extracting PDF: Topic 3_Multistage Transistor Amplifiers (2).pdf\n",
            "Extracting PDF: Topic 3_Bipolar Junction Transistors (2) (2).pdf\n",
            "Extracting PDF: LECTURE 4-EQUIVALENT CIRCUITS_TRANSFORMERS  (2).pdf\n",
            "Extracting PDF: Lecture 2_Large Signal Amplifiers_1 of 2 (2).pdf\n",
            "Extracting PDF: Q5 (2).pdf\n",
            "Extracting PDF: SMA 3121 Topic 7 Laurent series (1) (2).pdf\n",
            "Extracting PDF: LECTURE 1-MAGNETIC CIRCUITS (2).pdf\n",
            "Extracting PDF: LECTURE 6-DC MACHINE FUNDAMENTALS (2).pdf\n",
            "Extracting PDF: Lecture 7-Filters (2).pdf\n",
            "Extracting PDF: Topic 3_Single Stage Transistor Amplifiers (3).pdf\n",
            "Extracting PDF: Lecture 3_Large Signal Amplifiers_2 of 2 (2).pdf\n",
            "Extracting PDF: SMA 3121 Topic 9 Using Residue (1) (2).pdf\n",
            "Extracting PDF: MAGNETIC FLUX DENSITY (2).pdf\n",
            "Extracting PDF: V.K-Mehta-Principles-of-Electronics (2).pdf\n",
            "Extracting PDF: Q1to4 (2).pdf\n",
            "Extracting PDF: model.solutions (2).pdf\n",
            "Extracting PDF: SMA 3121 Topic 4 Cauchy formular (1) (2).pdf\n",
            "Extracting PDF: LECTURE 3-PRACTICAL TRANSFORMERS (2).pdf\n",
            "Extracting PDF: LECTURE 2-TRANSFORMERS (2).pdf\n",
            "Extracting PDF: Lecture 05_Three Phase AC circuits (2).pdf\n",
            "\n",
            "✔ Extraction complete!\n",
            "Total loaded documents: 73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next we will split the documents into chunks before building the FAISS AND EMBEDDINGS"
      ],
      "metadata": {
        "id": "A5WrXbE1m8Sr"
      },
      "id": "A5WrXbE1m8Sr"
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATING THE SPLITTER\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Recursive splitter -- best for mixed text types\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    separators=[\n",
        "        \"\\n\\n\",  # prefer splitting at paragraphs\n",
        "        \"\\n\",\n",
        "        \". \",\n",
        "        \"! \",\n",
        "        \"? \",\n",
        "        \"; \",\n",
        "        \", \",\n",
        "        \" \",    # fallback: whitespace\n",
        "        \"\"      # absolute fallback\n",
        "    ]\n",
        ")\n",
        "\n",
        "all_chunks = {}  # filename → list of text chunks\n",
        "\n",
        "for filename, text in documents.items():\n",
        "    print(f\"Chunking: {filename}\")\n",
        "\n",
        "    chunks = splitter.split_text(text)\n",
        "    all_chunks[filename] = chunks\n",
        "\n",
        "print(\"\\n✔ Chunking complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu5GP1Wwm50u",
        "outputId": "41e87539-cf12-46f3-8865-564eb6ea91f4"
      },
      "id": "tu5GP1Wwm50u",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunking: 1. Amplifiers with Negative Feedback (2).pdf\n",
            "Chunking: 3.1 Resources  (2).pdf\n",
            "Chunking: churchillbrown (2).pdf\n",
            "Chunking: EEE 3208 ELECTROMAGNETICS III lec1 notes (2).pdf\n",
            "Chunking: eee.eti.3104.cat.ii.make_up.ms (2).pdf\n",
            "Chunking: eee3102 [1-20] (2).pdf\n",
            "Chunking: EEE 2206_EET 2204_Electromagnetics I_Exam (2).pdf\n",
            "Chunking: eee3102 [21-33] (2).pdf\n",
            "Chunking: EEE_ETI3105_Assignment ONE (2).pdf\n",
            "Chunking: Design_of_Analog_Filters_Rolf_Schaumann (2).pdf\n",
            "Chunking: digielec (2).pdf\n",
            "Chunking: EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (3).pdf\n",
            "Chunking: eee3104eti3104 [1-68] (2).pdf\n",
            "Chunking: Electromagnetics (2).pdf\n",
            "Chunking: A textbook of Electrical Technology B. L. Thereja All Volumes ( PDFDrive (2).pdf\n",
            "Chunking: EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 (2).pdf\n",
            "Chunking: EEE 3208 ELECTROMAGNETICS IIILecture 2 3 and4 notes (1) (2).pdf\n",
            "Chunking: EEE2205 Electromagnetics I (2).pdf\n",
            "Chunking: 3.2 Past Papers   (2).pdf\n",
            "Chunking: EEE 3207 ELECTRICAL MACHINES 2 (2).pptx\n",
            "Chunking: Complex analysis Q&A (2).pdf\n",
            "Chunking: eee3102 [49-67] (2).pdf\n",
            "Chunking: EEE 3101_Analogue Electronics_Exam (2).pdf\n",
            "Chunking: EEE_ETI3105_CAT 2 (2).pdf\n",
            "Chunking: DOC-20250908-WA0053. (2).pdf\n",
            "Chunking: EEE2206cbd ELECTROMAGNETICS I (2).pdf\n",
            "Chunking: DOC-20250827-WA0009. (2).pdf\n",
            "Chunking: Complex analysis Q&A2 (2).pdf\n",
            "Chunking: EEE2205 Electromagnetics I ready (2).pdf\n",
            "Chunking: Electromagnetic_Field_Theory_U_A_Bakshi. - By EasyEngineering.net (2).pdf\n",
            "Chunking: Electronics Fundamentals Circuits Devices and Applications 8th Edition By David M Buchla and Thomas L Floyd (2).pdf\n",
            "Chunking: assignment_1 (2).pdf\n",
            "Chunking: EEE 2305 - Electromagnetics I - Exam - 2017-18 sem I (2) (2).pdf\n",
            "Chunking: eee.eti.3104.model.solutions.cat.ii (2).pdf\n",
            "Chunking: Document from . (2).pdf\n",
            "Chunking: applied-numerical-methods-with-matlab-for-engineers-and-scientists-4nbsped-0073397962-9780073397962_compress (2).pdf\n",
            "Chunking: EEE_ETI 3101_SUP_EXAM_ANALOGUE ELECTRONICS 1 ready (2).pdf\n",
            "Chunking: eee3104eti3104 (2).pdf\n",
            "Chunking: elecmag-i-electromagnetics... (2).pdf\n",
            "Chunking: EEE 3101cbd_ANALOGUE ELECTRONICS I EXAM 2019-2020 (2).pdf\n",
            "Chunking: EEE 3103 ELECTROMAGNETICS II (2).pdf\n",
            "Chunking: guru_b-s-_hiziroglu_h-r-_electromagnetic_field_bookzz-org (2).pdf\n",
            "Chunking: Lecture 1_BJT Configurations & Their Characteristics (2).pdf\n",
            "Chunking: Lecture 8-Laplace Transform (2).pdf\n",
            "Chunking: LECTURE 5-TRANSFORMER TESTS & EFFICIENCY (2).pdf\n",
            "Chunking: Numerical-Methods-Rao-V.-Dukkipati-2010 (2).pdf\n",
            "Chunking: Sadiqu (2).pdf\n",
            "Chunking: LECTURE 8-DC MOTORS (2).pdf\n",
            "Chunking: Topic 3_Single Stage Transistor Amplifiers (1) (2).pdf\n",
            "Chunking: LECTURE 7-TYPES OF DC GENERATORS (2).pdf\n",
            "Chunking: Topic 4_MOSFETS (2).pdf\n",
            "Chunking: Topic 2_Small Signal Amplifiers (2).pdf\n",
            "Chunking: SMA 3121 Topic 10 Conformal (1) (2).pdf\n",
            "Chunking: Topic 3_Multistage Transistor Amplifiers (2).pdf\n",
            "Chunking: Topic 3_Bipolar Junction Transistors (2) (2).pdf\n",
            "Chunking: LECTURE 4-EQUIVALENT CIRCUITS_TRANSFORMERS  (2).pdf\n",
            "Chunking: Lecture 2_Large Signal Amplifiers_1 of 2 (2).pdf\n",
            "Chunking: Q5 (2).pdf\n",
            "Chunking: SMA 3121 Topic 7 Laurent series (1) (2).pdf\n",
            "Chunking: LECTURE 1-MAGNETIC CIRCUITS (2).pdf\n",
            "Chunking: LECTURE 6-DC MACHINE FUNDAMENTALS (2).pdf\n",
            "Chunking: Lecture 7-Filters (2).pdf\n",
            "Chunking: Topic 3_Single Stage Transistor Amplifiers (3).pdf\n",
            "Chunking: Lecture 3_Large Signal Amplifiers_2 of 2 (2).pdf\n",
            "Chunking: SMA 3121 Topic 9 Using Residue (1) (2).pdf\n",
            "Chunking: MAGNETIC FLUX DENSITY (2).pdf\n",
            "Chunking: V.K-Mehta-Principles-of-Electronics (2).pdf\n",
            "Chunking: Q1to4 (2).pdf\n",
            "Chunking: model.solutions (2).pdf\n",
            "Chunking: SMA 3121 Topic 4 Cauchy formular (1) (2).pdf\n",
            "Chunking: LECTURE 3-PRACTICAL TRANSFORMERS (2).pdf\n",
            "Chunking: LECTURE 2-TRANSFORMERS (2).pdf\n",
            "Chunking: Lecture 05_Three Phase AC circuits (2).pdf\n",
            "\n",
            "✔ Chunking complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding and FAISS"
      ],
      "metadata": {
        "id": "2dtDUEjOsFVN"
      },
      "id": "2dtDUEjOsFVN"
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# FREE embedding model\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def embed_text(texts):\n",
        "    return embedding_model.encode(texts, convert_to_numpy=True)\n"
      ],
      "metadata": {
        "id": "IYq4LT24sO1e"
      },
      "id": "IYq4LT24sO1e",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the faiss vector store\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Flatten chunks\n",
        "texts = []\n",
        "meta = []\n",
        "for filename, chunks in all_chunks.items():\n",
        "    for chunk in chunks:\n",
        "        texts.append(chunk)\n",
        "        meta.append({\"source\": filename})\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = embed_text(texts)\n",
        "\n",
        "# Build FAISS index\n",
        "dim = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(embeddings)\n",
        "\n",
        "print(f\"FAISS index size: {index.ntotal}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVL8xyQYwUV1",
        "outputId": "cec66d8e-3098-4237-d659-749e892f0fa4"
      },
      "id": "TVL8xyQYwUV1",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index size: 22293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "FAISS_PATH = \"/content/drive/MyDrive/jarvis-ai/faiss_index\"\n",
        "\n",
        "np.save(FAISS_PATH + \"_vectors.npy\", embeddings)\n",
        "with open(FAISS_PATH + \"_metadata.pkl\", \"wb\") as f:\n",
        "    pickle.dump(meta, f)\n",
        "\n",
        "faiss.write_index(index, FAISS_PATH + \"_index.faiss\")\n",
        "\n",
        "print(\"✔ Vectorstore saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4XCGVF9ABm8",
        "outputId": "99117d8a-58ef-461e-c9f0-173a7f22d054"
      },
      "id": "D4XCGVF9ABm8",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Vectorstore saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "# Download the model file if it doesn't exist\n",
        "model_name = \"llama-3.1-8b-instruct.Q4_K_M.gguf\"\n",
        "model_path = f\"/content/{model_name}\"\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Downloading {model_name}...\")\n",
        "    !wget https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf -O {model_path}\n",
        "    print(\"Download complete.\")\n",
        "else:\n",
        "    print(f\"{model_name} already exists.\")\n",
        "\n",
        "# Load a quantized free model\n",
        "model = Llama(\n",
        "    model_path=model_path,\n",
        "    n_gpu_layers=20,   # GPU acceleration if available\n",
        "    n_ctx=4096\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROof42ziAaTY",
        "outputId": "5e983abb-b65d-46f9-844b-d3ea92199e31"
      },
      "id": "ROof42ziAaTY",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading llama-3.1-8b-instruct.Q4_K_M.gguf...\n",
            "--2025-11-29 09:47:35--  https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 3.165.160.11, 3.165.160.61, 3.165.160.59, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.165.160.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/669fd7d6059d4083c2921cad/31219bad9810fe4b16c087add07ad6169d449be16e82a1e613a1c2b78113c6e9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251129%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251129T094735Z&X-Amz-Expires=3600&X-Amz-Signature=d913d39d7b22642e4efb0a911a8eabd206906eb761469e0e70c8be92d29aff5d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf%3B+filename%3D%22Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf%22%3B&x-id=GetObject&Expires=1764413255&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDQxMzI1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjlmZDdkNjA1OWQ0MDgzYzI5MjFjYWQvMzEyMTliYWQ5ODEwZmU0YjE2YzA4N2FkZDA3YWQ2MTY5ZDQ0OWJlMTZlODJhMWU2MTNhMWMyYjc4MTEzYzZlOSoifV19&Signature=cFR60z3tEmsJnKXX2jvm2Bvi6qVZJPkHK3IUl9wOHFbY7EX16QYv-z7fK4UCrGF%7E3t6kf4RB-KczokETxvpxp1Ixi%7ELq0arp2JRZhS2ujoOp3SL23OthYxjAl%7EBBKRA7Bv7NnztMTSurIloMARhH0dXVRGKqeRaDOfYE0Fu01zRNdXPgJPTtz8PX7U0yrvJrUCGmomsnjLYrTqfzPR1tKO66qAeZ8r6WiB9KvGMeoplF8ChqmSrjBHXbGVF4%7EpvwglO0wiA-MvBeFSo9Hce0fncxcxKJPrax4LhZLb3zf-Cew2tO2VnUGyY%7EghcdWU1-YJqGKph8%7EDHbCRcDib153g__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-11-29 09:47:35--  https://cas-bridge.xethub.hf.co/xet-bridge-us/669fd7d6059d4083c2921cad/31219bad9810fe4b16c087add07ad6169d449be16e82a1e613a1c2b78113c6e9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251129%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251129T094735Z&X-Amz-Expires=3600&X-Amz-Signature=d913d39d7b22642e4efb0a911a8eabd206906eb761469e0e70c8be92d29aff5d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf%3B+filename%3D%22Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf%22%3B&x-id=GetObject&Expires=1764413255&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDQxMzI1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjlmZDdkNjA1OWQ0MDgzYzI5MjFjYWQvMzEyMTliYWQ5ODEwZmU0YjE2YzA4N2FkZDA3YWQ2MTY5ZDQ0OWJlMTZlODJhMWU2MTNhMWMyYjc4MTEzYzZlOSoifV19&Signature=cFR60z3tEmsJnKXX2jvm2Bvi6qVZJPkHK3IUl9wOHFbY7EX16QYv-z7fK4UCrGF%7E3t6kf4RB-KczokETxvpxp1Ixi%7ELq0arp2JRZhS2ujoOp3SL23OthYxjAl%7EBBKRA7Bv7NnztMTSurIloMARhH0dXVRGKqeRaDOfYE0Fu01zRNdXPgJPTtz8PX7U0yrvJrUCGmomsnjLYrTqfzPR1tKO66qAeZ8r6WiB9KvGMeoplF8ChqmSrjBHXbGVF4%7EpvwglO0wiA-MvBeFSo9Hce0fncxcxKJPrax4LhZLb3zf-Cew2tO2VnUGyY%7EghcdWU1-YJqGKph8%7EDHbCRcDib153g__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.238.217.64, 18.238.217.88, 18.238.217.63, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.238.217.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4920739168 (4.6G)\n",
            "Saving to: ‘/content/llama-3.1-8b-instruct.Q4_K_M.gguf’\n",
            "\n",
            "/content/llama-3.1- 100%[===================>]   4.58G  80.9MB/s    in 65s     \n",
            "\n",
            "2025-11-29 09:48:40 (72.1 MB/s) - ‘/content/llama-3.1-8b-instruct.Q4_K_M.gguf’ saved [4920739168/4920739168]\n",
            "\n",
            "Download complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 33 key-value pairs and 292 tensors from /content/llama-3.1-8b-instruct.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8B Instruct\n",
            "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
            "llama_model_loader: - kv   4:                           general.basename str              = Meta-Llama-3.1\n",
            "llama_model_loader: - kv   5:                         general.size_label str              = 8B\n",
            "llama_model_loader: - kv   6:                            general.license str              = llama3.1\n",
            "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
            "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
            "llama_model_loader: - kv   9:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - kv  28:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  29:                      quantize.imatrix.file str              = /models_out/Meta-Llama-3.1-8B-Instruc...\n",
            "llama_model_loader: - kv  30:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
            "llama_model_loader: - kv  31:             quantize.imatrix.entries_count i32              = 224\n",
            "llama_model_loader: - kv  32:              quantize.imatrix.chunks_count i32              = 125\n",
            "llama_model_loader: - type  f32:   66 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 4.58 GiB (4.89 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
            "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
            "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
            "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
            "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
            "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
            "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
            "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
            "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
            "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
            "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
            "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
            "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
            "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
            "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
            "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
            "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
            "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
            "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
            "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
            "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
            "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
            "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
            "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
            "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
            "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
            "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
            "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
            "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
            "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
            "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
            "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
            "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
            "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
            "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
            "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
            "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
            "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
            "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
            "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
            "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
            "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
            "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
            "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
            "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
            "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
            "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
            "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
            "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
            "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
            "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
            "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
            "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
            "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
            "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
            "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
            "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
            "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
            "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
            "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
            "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
            "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
            "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
            "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
            "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
            "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
            "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
            "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
            "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
            "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
            "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
            "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
            "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
            "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
            "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
            "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
            "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
            "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
            "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
            "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
            "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
            "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
            "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
            "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
            "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
            "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
            "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
            "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
            "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
            "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
            "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
            "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
            "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
            "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
            "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
            "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
            "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
            "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
            "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
            "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
            "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
            "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
            "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
            "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
            "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
            "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
            "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
            "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
            "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
            "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
            "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
            "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
            "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
            "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
            "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
            "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
            "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
            "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
            "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
            "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
            "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
            "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
            "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
            "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
            "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
            "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
            "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
            "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
            "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
            "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
            "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
            "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
            "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
            "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
            "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
            "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
            "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
            "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
            "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
            "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
            "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
            "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
            "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
            "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
            "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
            "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
            "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
            "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
            "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
            "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
            "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
            "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
            "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
            "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
            "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
            "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
            "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
            "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
            "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
            "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
            "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
            "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
            "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
            "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
            "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
            "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
            "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
            "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
            "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
            "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
            "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
            "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
            "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
            "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
            "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
            "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
            "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
            "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
            "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
            "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
            "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
            "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
            "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
            "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
            "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
            "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
            "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
            "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
            "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
            "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
            "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
            "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
            "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
            "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
            "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
            "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
            "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
            "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
            "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
            "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
            "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
            "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
            "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
            "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
            "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
            "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
            "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
            "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
            "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
            "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
            "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
            "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
            "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
            "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
            "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
            "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
            "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
            "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
            "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
            "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
            "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
            "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
            "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
            "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
            "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
            "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
            "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
            "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
            "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
            "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
            "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
            "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
            "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
            "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
            "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
            "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
            "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
            "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
            "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
            "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
            "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
            "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
            "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
            "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
            "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
            "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
            "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
            "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
            "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
            "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
            "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
            "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
            "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
            "load: printing all EOG tokens:\n",
            "load:   - 128001 ('<|end_of_text|>')\n",
            "load:   - 128008 ('<|eom_id|>')\n",
            "load:   - 128009 ('<|eot_id|>')\n",
            "load: special tokens cache size = 256\n",
            "load: token to piece cache size = 0.7999 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 131072\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: is_swa_any       = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 500000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 131072\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: model type       = 8B\n",
            "print_info: model params     = 8.03 B\n",
            "print_info: general.name     = Meta Llama 3.1 8B Instruct\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 128256\n",
            "print_info: n_merges         = 280147\n",
            "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
            "print_info: EOS token        = 128009 '<|eot_id|>'\n",
            "print_info: EOT token        = 128009 '<|eot_id|>'\n",
            "print_info: EOM token        = 128008 '<|eom_id|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
            "print_info: EOG token        = 128008 '<|eom_id|>'\n",
            "print_info: EOG token        = 128009 '<|eot_id|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 130 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
            "load_tensors:   CPU_REPACK model buffer size =  3204.00 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =  4685.30 MiB\n",
            "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_v.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.28.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.28.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.29.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.29.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.30.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.31.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.31.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.ffn_up.weight with q4_K_8x8\n",
            "....................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 4096\n",
            "llama_context: n_ctx_per_seq = 4096\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: kv_unified    = false\n",
            "llama_context: freq_base     = 500000.0\n",
            "llama_context: freq_scale    = 1\n",
            "llama_context: n_ctx_per_seq (4096) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:        CPU  output buffer size =     0.49 MiB\n",
            "create_memory: n_ctx = 4096 (padded)\n",
            "llama_kv_cache_unified: layer   0: dev = CPU\n",
            "llama_kv_cache_unified: layer   1: dev = CPU\n",
            "llama_kv_cache_unified: layer   2: dev = CPU\n",
            "llama_kv_cache_unified: layer   3: dev = CPU\n",
            "llama_kv_cache_unified: layer   4: dev = CPU\n",
            "llama_kv_cache_unified: layer   5: dev = CPU\n",
            "llama_kv_cache_unified: layer   6: dev = CPU\n",
            "llama_kv_cache_unified: layer   7: dev = CPU\n",
            "llama_kv_cache_unified: layer   8: dev = CPU\n",
            "llama_kv_cache_unified: layer   9: dev = CPU\n",
            "llama_kv_cache_unified: layer  10: dev = CPU\n",
            "llama_kv_cache_unified: layer  11: dev = CPU\n",
            "llama_kv_cache_unified: layer  12: dev = CPU\n",
            "llama_kv_cache_unified: layer  13: dev = CPU\n",
            "llama_kv_cache_unified: layer  14: dev = CPU\n",
            "llama_kv_cache_unified: layer  15: dev = CPU\n",
            "llama_kv_cache_unified: layer  16: dev = CPU\n",
            "llama_kv_cache_unified: layer  17: dev = CPU\n",
            "llama_kv_cache_unified: layer  18: dev = CPU\n",
            "llama_kv_cache_unified: layer  19: dev = CPU\n",
            "llama_kv_cache_unified: layer  20: dev = CPU\n",
            "llama_kv_cache_unified: layer  21: dev = CPU\n",
            "llama_kv_cache_unified: layer  22: dev = CPU\n",
            "llama_kv_cache_unified: layer  23: dev = CPU\n",
            "llama_kv_cache_unified: layer  24: dev = CPU\n",
            "llama_kv_cache_unified: layer  25: dev = CPU\n",
            "llama_kv_cache_unified: layer  26: dev = CPU\n",
            "llama_kv_cache_unified: layer  27: dev = CPU\n",
            "llama_kv_cache_unified: layer  28: dev = CPU\n",
            "llama_kv_cache_unified: layer  29: dev = CPU\n",
            "llama_kv_cache_unified: layer  30: dev = CPU\n",
            "llama_kv_cache_unified: layer  31: dev = CPU\n",
            "llama_kv_cache_unified:        CPU KV buffer size =   512.00 MiB\n",
            "llama_kv_cache_unified: size =  512.00 MiB (  4096 cells,  32 layers,  1/1 seqs), K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 1\n",
            "llama_context: max_nodes = 2336\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "llama_context:        CPU compute buffer size =   300.01 MiB\n",
            "llama_context: graph nodes  = 1126\n",
            "llama_context: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "Model metadata: {'quantize.imatrix.entries_count': '224', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'quantize.imatrix.chunks_count': '125', 'quantize.imatrix.file': '/models_out/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct.imatrix', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \"Tools: \" + builtin_tools | reject(\\'equalto\\', \\'code_interpreter\\') | join(\", \") + \"\\\\n\\\\n\"}}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + \\'=\"\\' + arg_val + \\'\"\\' }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \")\" }}\\n        {%- else  %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n            {{- \\'\"parameters\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \"}\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we\\'re in ipython mode #}\\n            {{- \"<|eom_id|>\" }}\\n        {%- else %}\\n            {{- \"<|eot_id|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '15', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '500000.000000', 'general.architecture': 'llama', 'general.basename': 'Meta-Llama-3.1', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Meta Llama 3.1 8B Instruct', 'general.finetune': 'Instruct', 'general.type': 'model', 'general.size_label': '8B', 'general.license': 'llama3.1', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Using gguf chat template: {{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- set date_string = \"26 Jul 2024\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content']|trim %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message + builtin tools #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
            "{%- if builtin_tools is defined or tools is not none %}\n",
            "    {{- \"Environment: ipython\\n\" }}\n",
            "{%- endif %}\n",
            "{%- if builtin_tools is defined %}\n",
            "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content']|trim %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
            "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
            "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- endif %}\n",
            "                {%- endfor %}\n",
            "            {{- \")\" }}\n",
            "        {%- else  %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "            {{- '\"parameters\": ' }}\n",
            "            {{- tool_call.arguments | tojson }}\n",
            "            {{- \"}\" }}\n",
            "        {%- endif %}\n",
            "        {%- if builtin_tools is defined %}\n",
            "            {#- This means we're in ipython mode #}\n",
            "            {{- \"<|eom_id|>\" }}\n",
            "        {%- else %}\n",
            "            {{- \"<|eot_id|>\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
            "{%- endif %}\n",
            "\n",
            "Using chat eos_token: <|eot_id|>\n",
            "Using chat bos_token: <|begin_of_text|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Load free embedding model\n",
        "embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Example: your text chunks should be stored in `chunks` list\n",
        "# chunks = [\"text1...\", \"text2...\", ...]\n",
        "\n",
        "print(f\"Total Chunks to Embed: {len(chunks)}\")\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = embedder.encode(chunks, show_progress_bar=True, convert_to_numpy=True)\n",
        "\n",
        "print(\"Embedding shape:\", embeddings.shape)\n",
        "\n",
        "# Save embeddings + chunks\n",
        "output_folder = \"/content/drive/MyDrive/jarvis-ai/embeddings\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "np.save(os.path.join(output_folder, \"chunk_embeddings.npy\"), embeddings)\n",
        "\n",
        "with open(os.path.join(output_folder, \"chunks.json\"), \"w\") as f:\n",
        "    json.dump(chunks, f)\n",
        "\n",
        "print(\"Embeddings + chunk text saved to Google Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "71de361e34964e25aefa18a9fad65dbb",
            "7eb9ba1c2e0b4f928e27b3b023b85609",
            "a33bd7e396b140c0b7eed3522035b928",
            "f88c2bd9a47c4925a2ec1df82fc0db48",
            "3e593e83cb7945aea33346acf9d3517a",
            "c4b9fc2a5ca94f12a0208b12e6e11f68",
            "0f4dafd381a447faade5ec86b2902262",
            "c6a83748c53f4a9aa235bbae233d9294",
            "17aecae4df9f42a895d188f88a10421f",
            "9609f6a2ffa242a7909877c854cc2339",
            "e0c7722f63254ca69cc8455712f7d7d7"
          ]
        },
        "id": "6LIBV4dGAiPq",
        "outputId": "64f146b3-4506-44e3-af1e-019619b63047"
      },
      "id": "6LIBV4dGAiPq",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Chunks to Embed: 22\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71de361e34964e25aefa18a9fad65dbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding shape: (22, 384)\n",
            "Embeddings + chunk text saved to Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, numpy as np\n",
        "\n",
        "# importing chunks from google drive.\n",
        "DRIVE_BASE = \"/content/drive/MyDrive/jarvis-ai/embeddings\"\n",
        "chunks_path = os.path.join(DRIVE_BASE, \"chunks.json\")\n",
        "emb_path = os.path.join(DRIVE_BASE, \"chunk_embeddings.npy\")\n",
        "meta_path = os.path.join(DRIVE_BASE, \"metadata.json\")  # optional: if you stored metadata\n",
        "\n",
        "# Load\n",
        "with open(chunks_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    chunks = json.load(f)  # list of strings (chunk texts)\n",
        "\n",
        "embeddings = np.load(emb_path)  # shape: (N, dim)\n",
        "\n",
        "# Optional metadata mapping (source filename, chunk index)\n",
        "metadata = None\n",
        "if os.path.exists(meta_path):\n",
        "    with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        metadata = json.load(f)  # expected list/dict aligned with chunks\n",
        "\n",
        "print(f\"Loaded {len(chunks)} chunks, embeddings shape = {embeddings.shape}\")\n",
        "if metadata:\n",
        "    print(f\"Loaded metadata entries: {len(metadata)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrCTpHp-F6_p",
        "outputId": "eaa1e8e1-06b5-48e4-bde8-9359d43e902f"
      },
      "id": "TrCTpHp-F6_p",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 22 chunks, embeddings shape = (22, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "# Ensure embeddings are float32\n",
        "emb = embeddings.astype('float32')\n",
        "# Normalize to unit vectors for cosine similarity\n",
        "faiss.normalize_L2(emb)\n",
        "\n",
        "d = emb.shape[1]  # embedding dim\n",
        "\n",
        "# Create index (inner product) and add vectors\n",
        "index = faiss.IndexFlatIP(d)   # inner product on normalized vectors = cosine similarity\n",
        "index.add(emb)\n",
        "print(\"FAISS index ntotal:\", index.ntotal)\n",
        "\n",
        "# Optionally save index to Drive for reuse\n",
        "DRIVE_BASE2 = \"/content/drive/MyDrive/jarvis-ai\"\n",
        "FAISS_INDEX_PATH = os.path.join(DRIVE_BASE2, \"faiss_index.faiss\")\n",
        "faiss.write_index(index, FAISS_INDEX_PATH)\n",
        "print(\"Saved FAISS index to:\", FAISS_INDEX_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbEXcBZ-GhIr",
        "outputId": "a127f3b8-c1e9-43cb-aa36-17cb05cd74c7"
      },
      "id": "RbEXcBZ-GhIr",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index ntotal: 22\n",
            "Saved FAISS index to: /content/drive/MyDrive/jarvis-ai/faiss_index.faiss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to load later\n",
        "# Load index\n",
        "index = faiss.read_index(FAISS_INDEX_PATH)\n"
      ],
      "metadata": {
        "id": "rGs5dw56Htaz"
      },
      "id": "rGs5dw56Htaz",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple semantic search\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Reuse MiniLM for query embeddings\n",
        "query_embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def semantic_search(query, k=5):\n",
        "    \"\"\"\n",
        "    Returns list of (score, chunk_text, metadata(optional), chunk_id).\n",
        "    Higher score = more similar (cosine).\n",
        "    \"\"\"\n",
        "    q_emb = query_embedder.encode([query], convert_to_numpy=True).astype('float32')\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    D, I = index.search(q_emb, k)  # D: similarities, I: indices\n",
        "    results = []\n",
        "    for score, idx in zip(D[0], I[0]):\n",
        "        if idx < 0:\n",
        "            continue\n",
        "        chunk_text = chunks[idx]\n",
        "        meta = metadata[idx] if (metadata and idx < len(metadata)) else None\n",
        "        results.append({\"score\": float(score), \"chunk_id\": idx, \"text\": chunk_text, \"meta\": meta})\n",
        "    return results\n",
        "\n",
        "# Quick test\n",
        "res = semantic_search(\"Explain Maxwell's equations\", k=3)\n",
        "for r in res:\n",
        "    print(\"score:\", r[\"score\"], \"meta:\", r[\"meta\"])\n",
        "    print(r[\"text\"][:400].replace(\"\\n\",\" \") + \"...\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoWsd_61HxCw",
        "outputId": "9a8927ec-cfbf-4e0d-af66-cf2420fc1138"
      },
      "id": "PoWsd_61HxCw",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score: 0.13774579763412476 meta: None\n",
            "120o apart and the whole rotated in a uniform magnetic field as  shown in Fig. The result is three independent supplies of equal  voltages which are each displaced by 120o from each other. • The convention adopted to identify each of the phase voltages  is: R-red, Y-yellow, and B-blue. • The phase-sequence is given by the sequence in which the  conductors pass the point initially taken by the red ...\n",
            "\n",
            "score: 0.13516506552696228 meta: None\n",
            "frequency is 50 Hz. • Qn. 3:Three similar coils, connected in star, take a total power of 1.5 kW at a p.f. of 0.2 lagging  from a 3-phase 400 V, 50 Hz supply. Calculate (i) the resistance and inductance of each coil and  (ii) the line currents if one of the coils is short-circuited. • Qn. 4: A star-connected balanced system with a line voltage of 300 V is supplying a balanced  Y-connected load of ...\n",
            "\n",
            "score: 0.11292943358421326 meta: None\n",
            "measured by two watt-meters method and the two watt-meters read 3 kW and 1 kW. Determine the  values of R and L connected in each phase. • Qn. 2: A Y-connected balanced load is supplied from a 3-phase balanced supply with a line voltage of  416 V at a frequency of 50 Hz. Each phase of the load consists of a resistance and a capacitor joined in  series and the readings on two watt-meters connected ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assembling a RAG prompt.\n",
        "# A naive char-based truncation strategy (safe fallback).\n",
        "def assemble_prompt(question, top_k_results, max_context_chars=3000):\n",
        "    \"\"\"\n",
        "    top_k_results: output of semantic_search\n",
        "    max_context_chars: maximum total characters across all context chunks\n",
        "    \"\"\"\n",
        "    intro = \"You are JARVIS, an expert teaching assistant for engineering. Use the context below to answer the question factually.\\n\\n\"\n",
        "    context = \"\"\n",
        "    chars_used = 0\n",
        "    for r in top_k_results:\n",
        "        chunk = r[\"text\"]\n",
        "        header = f\"[Source: {r['meta'].get('source') if r['meta'] else 'unknown'} | chunk_id: {r['chunk_id']} | score: {r['score']:.3f}]\\n\"\n",
        "        # if adding this chunk will exceed the budget, take a prefix of the chunk\n",
        "        if chars_used + len(chunk) + len(header) > max_context_chars:\n",
        "            remaining = max_context_chars - chars_used - len(header)\n",
        "            if remaining <= 0:\n",
        "                break\n",
        "            chunk = chunk[:remaining]\n",
        "        context += header + chunk + \"\\n\\n\"\n",
        "        chars_used += len(header) + len(chunk)\n",
        "    prompt = intro + \"Context:\\n\" + context + \"\\nQuestion: \" + question + \"\\nAnswer concisely and cite relevant sources in brackets when possible.\"\n",
        "    return prompt\n",
        "\n",
        "# Example\n",
        "top = semantic_search(\"What is a bilinear transfer function?\", k=5)\n",
        "prompt = assemble_prompt(\"Explain bilinear transfer functions and give an example.\", top, max_context_chars=3000)\n",
        "print(prompt[:1500])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt-3DVHtKEHS",
        "outputId": "45a93c67-41ba-48f0-b84f-bb62dd089341"
      },
      "id": "yt-3DVHtKEHS",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are JARVIS, an expert teaching assistant for engineering. Use the context below to answer the question factually.\n",
            "\n",
            "Context:\n",
            "[Source: unknown | chunk_id: 7 | score: 0.213]\n",
            "•\n",
            "Phase current: the current flowing through each phase in a three-phase load.\n",
            "•\n",
            "Line current: the current flowing from the generator to the load in each transmission line in \n",
            "a three phase system.\n",
            "•\n",
            "Balanced phase voltages: these are phase voltages equal in magnitude and are out of phase \n",
            "with each other by 120o.\n",
            "•\n",
            "Balanced load: a balanced load is one in which the phase impedances are equal in \n",
            "magnitude and in phase.\n",
            "•\n",
            "Phase sequence: The order in which the voltages in the three phases (or coils) of an \n",
            "alternator reach their maximum positive values is called phase sequence or phase order.\n",
            "11\n",
            "Star or Wye (Y) Connected System\n",
            "•\n",
            "In this method, similar ends (start or finish) of the three phases of the alternator are joined \n",
            "together to form a common junction N as shown in Fig. (a)\n",
            "•\n",
            "The common junction N is called the star point or neutral point. The three line conductors \n",
            "are run from the three ends (finish ends F in this case) and are designated as R, Y and B. \n",
            "•\n",
            "\n",
            "[Source: unknown | chunk_id: 8 | score: 0.203]\n",
            "•\n",
            "The common junction N is called the star point or neutral point. The three line conductors \n",
            "are run from the three ends (finish ends F in this case) and are designated as R, Y and B. \n",
            "•\n",
            "This constitutes a 3-phase, 3-wire star-connected system. \n",
            "•\n",
            "The voltage between any line and the neutral po\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "71de361e34964e25aefa18a9fad65dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7eb9ba1c2e0b4f928e27b3b023b85609",
              "IPY_MODEL_a33bd7e396b140c0b7eed3522035b928",
              "IPY_MODEL_f88c2bd9a47c4925a2ec1df82fc0db48"
            ],
            "layout": "IPY_MODEL_3e593e83cb7945aea33346acf9d3517a"
          }
        },
        "7eb9ba1c2e0b4f928e27b3b023b85609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4b9fc2a5ca94f12a0208b12e6e11f68",
            "placeholder": "​",
            "style": "IPY_MODEL_0f4dafd381a447faade5ec86b2902262",
            "value": "Batches: 100%"
          }
        },
        "a33bd7e396b140c0b7eed3522035b928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6a83748c53f4a9aa235bbae233d9294",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17aecae4df9f42a895d188f88a10421f",
            "value": 1
          }
        },
        "f88c2bd9a47c4925a2ec1df82fc0db48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9609f6a2ffa242a7909877c854cc2339",
            "placeholder": "​",
            "style": "IPY_MODEL_e0c7722f63254ca69cc8455712f7d7d7",
            "value": " 1/1 [00:03&lt;00:00,  3.90s/it]"
          }
        },
        "3e593e83cb7945aea33346acf9d3517a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4b9fc2a5ca94f12a0208b12e6e11f68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f4dafd381a447faade5ec86b2902262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6a83748c53f4a9aa235bbae233d9294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17aecae4df9f42a895d188f88a10421f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9609f6a2ffa242a7909877c854cc2339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c7722f63254ca69cc8455712f7d7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}